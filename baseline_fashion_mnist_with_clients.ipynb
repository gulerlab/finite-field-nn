{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_augment_aggregate(loader, num_of_clients):\n",
    "    data, labels = next(iter(loader))\n",
    "\n",
    "    partite_class_data = []\n",
    "    partite_class_labels = []\n",
    "    for class_idx in range(10):\n",
    "        mask = labels == class_idx\n",
    "        len_mask = torch.count_nonzero(mask)\n",
    "        remainder = len_mask % num_of_clients\n",
    "        split_param = (len_mask // num_of_clients + 1) if remainder != 0 else (len_mask / num_of_clients)\n",
    "        partite_class_data.append(torch.split(data[mask], split_param))\n",
    "        partite_class_labels.append(torch.split(labels[mask], split_param))\n",
    "\n",
    "    partite_clients_data = []\n",
    "    partite_clients_labels = []\n",
    "    for client_idx in range(num_of_clients):\n",
    "        client_data_buffer = []\n",
    "        client_labels_buffer = []\n",
    "        for class_idx in range(10):\n",
    "            client_data_buffer.append(partite_class_data[class_idx][client_idx])\n",
    "            client_labels_buffer.append(partite_class_labels[class_idx][client_idx])\n",
    "        client_data_buffer = torch.concatenate(client_data_buffer)\n",
    "        client_labels_buffer = torch.concatenate(client_labels_buffer)\n",
    "        \n",
    "        #normalize client data\n",
    "        client_data_buffer = (client_data_buffer - torch.mean(client_data_buffer)) / torch.std(client_data_buffer)\n",
    "        partite_clients_data.append(client_data_buffer.reshape(client_data_buffer.shape[0], -1))\n",
    "        partite_clients_labels.append(client_labels_buffer)\n",
    "    permute_data = torch.randperm(data.shape[0])\n",
    "    data = torch.concatenate(partite_clients_data)[permute_data]\n",
    "    labels = torch.concatenate(partite_clients_labels)[permute_data]\n",
    "    dataset = TensorDataset(data, labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_of_clients = 10\n",
    "transform = ToTensor()\n",
    "\n",
    "train_dataset = FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_dataset.data.shape[0])\n",
    "train_dataset = collect_augment_aggregate(train_loader, num_of_clients)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256)\n",
    "\n",
    "test_dataset = FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_dataset.data.shape[0])\n",
    "test_dataset = collect_augment_aggregate(test_loader, num_of_clients)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self, in_channel, hidden_channel, out_channel, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.lin_01 = nn.Linear(in_channel, hidden_channel, bias=False)\n",
    "        self.lin_02 = nn.Linear(hidden_channel, out_channel, bias=False)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.act(self.lin_01(x))\n",
    "        out = self.lin_02(out)\n",
    "        return out\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SimpleNetwork(784, 128, 10).to(device)\n",
    "optim = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4070942401885986\n",
      "accuracy: 0.45969998836517334\n",
      "2.002516269683838\n",
      "1.7913089990615845\n",
      "1.5901436805725098\n",
      "1.4349408149719238\n",
      "1.3121137619018555\n",
      "1.0941272974014282\n",
      "1.106682538986206\n",
      "0.9620117545127869\n",
      "0.9954046607017517\n",
      "0.8277041912078857\n",
      "accuracy: 0.705299973487854\n",
      "0.8617054224014282\n",
      "0.8327913284301758\n",
      "0.8126285076141357\n",
      "0.7945008873939514\n",
      "0.6554155349731445\n",
      "0.7608761191368103\n",
      "0.6622105836868286\n",
      "0.7318330407142639\n",
      "0.702953577041626\n",
      "0.6856306195259094\n",
      "accuracy: 0.7428999543190002\n",
      "0.7380772233009338\n",
      "0.7523606419563293\n",
      "0.6958063244819641\n",
      "0.6586880087852478\n",
      "0.6085900664329529\n",
      "0.7472221255302429\n",
      "0.5331209897994995\n",
      "0.5522488951683044\n",
      "0.5804660320281982\n",
      "0.5950310826301575\n",
      "accuracy: 0.774899959564209\n",
      "0.5883497595787048\n",
      "0.6424744129180908\n",
      "0.6575775742530823\n",
      "0.537688672542572\n",
      "0.689792275428772\n",
      "0.6021755337715149\n",
      "0.5667117834091187\n",
      "0.6010506749153137\n",
      "0.660700798034668\n",
      "0.5945851802825928\n",
      "accuracy: 0.7888000011444092\n",
      "0.5673952102661133\n",
      "0.6250730156898499\n",
      "0.5214952826499939\n",
      "0.5491254925727844\n",
      "0.5448571443557739\n",
      "0.6801533102989197\n",
      "0.5256052017211914\n",
      "0.5090610384941101\n",
      "0.5655804872512817\n",
      "0.5850202441215515\n",
      "accuracy: 0.7940999865531921\n",
      "0.48159074783325195\n",
      "0.5259917378425598\n",
      "0.6681097745895386\n",
      "0.5586174130439758\n",
      "0.42214125394821167\n",
      "0.5509094595909119\n",
      "0.5235112309455872\n",
      "0.5147636532783508\n",
      "0.5786245465278625\n",
      "0.4660077691078186\n",
      "accuracy: 0.8091999888420105\n",
      "0.46375325322151184\n",
      "0.5758174061775208\n",
      "0.47401535511016846\n",
      "0.4056726396083832\n",
      "0.4604184031486511\n",
      "0.4491364061832428\n",
      "0.4930761754512787\n",
      "0.4784911870956421\n",
      "0.48217320442199707\n",
      "0.5721685886383057\n",
      "accuracy: 0.8093000054359436\n",
      "0.5004569292068481\n",
      "0.508902370929718\n",
      "0.5232572555541992\n",
      "0.5078763365745544\n",
      "0.7034615278244019\n",
      "0.4899541735649109\n",
      "0.5340909957885742\n",
      "0.4741739332675934\n",
      "0.47855886816978455\n",
      "0.4587347209453583\n",
      "accuracy: 0.8097999691963196\n",
      "0.5025776028633118\n",
      "0.4444997310638428\n",
      "0.6301686763763428\n",
      "0.3669471740722656\n",
      "0.4795774221420288\n",
      "0.40889424085617065\n",
      "0.43252629041671753\n",
      "0.5208112597465515\n",
      "0.5411375761032104\n",
      "0.420547753572464\n",
      "accuracy: 0.8215000033378601\n",
      "0.5060192942619324\n",
      "0.444063663482666\n",
      "0.40379059314727783\n",
      "0.4572804868221283\n",
      "0.48400577902793884\n",
      "0.4751211404800415\n",
      "0.47302332520484924\n",
      "0.47080081701278687\n",
      "0.45328572392463684\n",
      "0.48877379298210144\n",
      "accuracy: 0.8244999647140503\n",
      "0.5471094250679016\n",
      "0.5324726104736328\n",
      "0.5091121196746826\n",
      "0.550457239151001\n",
      "0.5092450976371765\n",
      "0.4719405472278595\n",
      "0.4336707890033722\n",
      "0.44756028056144714\n",
      "0.43537163734436035\n",
      "0.3778317868709564\n",
      "accuracy: 0.8260999917984009\n",
      "0.36334848403930664\n",
      "0.5114573240280151\n",
      "0.4735081195831299\n",
      "0.3996419608592987\n",
      "0.48775407671928406\n",
      "0.44379106163978577\n",
      "0.4583965539932251\n",
      "0.4243820309638977\n",
      "0.4646867513656616\n",
      "0.4570133090019226\n",
      "accuracy: 0.8269000053405762\n",
      "0.4754355847835541\n",
      "0.4040117859840393\n",
      "0.47936907410621643\n",
      "0.4267755448818207\n",
      "0.402757853269577\n",
      "0.43703365325927734\n",
      "0.4055286645889282\n",
      "0.4626453220844269\n",
      "0.40917402505874634\n",
      "0.4949880540370941\n",
      "accuracy: 0.8310999870300293\n",
      "0.4543028771877289\n",
      "0.49443498253822327\n",
      "0.4448040723800659\n",
      "0.44555598497390747\n",
      "0.4263136684894562\n",
      "0.4966808557510376\n",
      "0.4651865065097809\n",
      "0.5748187303543091\n",
      "0.48521819710731506\n",
      "0.508357584476471\n",
      "accuracy: 0.8276999592781067\n",
      "0.42793193459510803\n",
      "0.44359642267227173\n",
      "0.4260613024234772\n",
      "0.41548457741737366\n",
      "0.4505820572376251\n",
      "0.4409087300300598\n",
      "0.4577581286430359\n",
      "0.32872137427330017\n",
      "0.45013824105262756\n",
      "0.39542901515960693\n",
      "accuracy: 0.8274999856948853\n",
      "0.4717915654182434\n",
      "0.43633028864860535\n",
      "0.4866490364074707\n",
      "0.41721540689468384\n",
      "0.423890620470047\n",
      "0.45978137850761414\n",
      "0.4224376082420349\n",
      "0.458315372467041\n",
      "0.5178889036178589\n",
      "0.4372889995574951\n",
      "accuracy: 0.832099974155426\n",
      "0.3456261157989502\n",
      "0.3759193420410156\n",
      "0.42594069242477417\n",
      "0.40107277035713196\n",
      "0.47388380765914917\n",
      "0.42592889070510864\n",
      "0.41372498869895935\n",
      "0.46823054552078247\n",
      "0.46828705072402954\n",
      "0.42017674446105957\n",
      "accuracy: 0.8335999846458435\n",
      "0.4296800494194031\n",
      "0.37394434213638306\n",
      "0.3820495009422302\n",
      "0.4215453267097473\n",
      "0.3240402042865753\n",
      "0.43456047773361206\n",
      "0.4160878360271454\n",
      "0.37196165323257446\n",
      "0.36599114537239075\n",
      "0.4413778781890869\n",
      "accuracy: 0.8362999558448792\n",
      "0.4926449656486511\n",
      "0.5197495818138123\n",
      "0.38431423902511597\n",
      "0.40499308705329895\n",
      "0.47790607810020447\n",
      "0.4799007177352905\n",
      "0.4284849464893341\n",
      "0.4930736720561981\n",
      "0.4956662654876709\n",
      "0.48100578784942627\n",
      "accuracy: 0.8321999907493591\n",
      "0.4143829941749573\n",
      "0.4187747836112976\n",
      "0.4468146562576294\n",
      "0.46640104055404663\n",
      "0.33256810903549194\n",
      "0.3964250683784485\n",
      "0.4950372874736786\n",
      "0.45941266417503357\n",
      "0.40953072905540466\n",
      "0.447567343711853\n",
      "accuracy: 0.8364999890327454\n",
      "0.3928196132183075\n",
      "0.41221117973327637\n",
      "0.3971620202064514\n",
      "0.3137645423412323\n",
      "0.39469584822654724\n",
      "0.3636096715927124\n",
      "0.4859917163848877\n",
      "0.4166930615901947\n",
      "0.469708651304245\n",
      "0.4517925977706909\n",
      "accuracy: 0.8410999774932861\n",
      "0.5174272656440735\n",
      "0.381130188703537\n",
      "0.43593934178352356\n",
      "0.46698611974716187\n",
      "0.5094913840293884\n",
      "0.4069245159626007\n",
      "0.37098872661590576\n",
      "0.49151667952537537\n",
      "0.4481930732727051\n",
      "0.4596504867076874\n",
      "accuracy: 0.842199981212616\n",
      "0.4597533643245697\n",
      "0.5218708515167236\n",
      "0.4750286340713501\n",
      "0.48246610164642334\n",
      "0.4553554654121399\n",
      "0.3644196391105652\n",
      "0.3517688810825348\n",
      "0.38722121715545654\n",
      "0.3876410126686096\n",
      "0.3711385130882263\n",
      "accuracy: 0.8411999940872192\n",
      "0.4271855354309082\n",
      "0.35769614577293396\n",
      "0.4328562021255493\n",
      "0.4388860762119293\n",
      "accuracy: 0.8359000086784363\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for iter_idx, (data, label) in enumerate(train_loader):\n",
    "    data, label = data.to(device), label.to(device)\n",
    "    optim.zero_grad()\n",
    "    preds = model(data)\n",
    "    loss = criterion(preds, label)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if iter_idx == 0 or (iter_idx % 10) == 0 or iter_idx == (len(train_loader) - 1):\n",
    "        model.eval()\n",
    "        tp_count = 0\n",
    "        val_size = 0\n",
    "        with torch.no_grad():\n",
    "            for val_iter_idx, (val_data, val_label) in enumerate(test_loader):\n",
    "                val_data, val_label = val_data.to(device), val_label.to(device)\n",
    "                val_preds = model(val_data)\n",
    "                val_preds = torch.argmax(val_preds, dim=1)\n",
    "                tp_count += torch.count_nonzero(val_label == val_preds)\n",
    "                val_size += val_data.shape[0]\n",
    "            print('accuracy: {}'.format((tp_count / val_size).item()))\n",
    "        model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

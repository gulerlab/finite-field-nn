{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_augment_aggregate(loader, num_of_clients):\n",
    "    data, labels = next(iter(loader))\n",
    "\n",
    "    partite_class_data = []\n",
    "    partite_class_labels = []\n",
    "    for class_idx in range(10):\n",
    "        mask = labels == class_idx\n",
    "        len_mask = torch.count_nonzero(mask)\n",
    "        remainder = len_mask % num_of_clients\n",
    "        split_param = len_mask // num_of_clients\n",
    "        partite_class_data.append(list(torch.split(data[mask][:-remainder], split_param)))\n",
    "        partite_class_labels.append(list(torch.split(labels[mask][:-remainder], split_param)))\n",
    "        for remainder_idx in range(remainder):\n",
    "            partite_class_data[-1][remainder_idx] = torch.concatenate([partite_class_data[-1][remainder_idx], data[mask][-remainder].unsqueeze(0)])\n",
    "            partite_class_labels[-1][remainder_idx] = torch.concatenate([partite_class_labels[-1][remainder_idx], labels[mask][-remainder].unsqueeze(0)])\n",
    "\n",
    "    partite_clients_data = []\n",
    "    partite_clients_labels = []\n",
    "    for client_idx in range(num_of_clients):\n",
    "        client_data_buffer = []\n",
    "        client_labels_buffer = []\n",
    "        for class_idx in range(10):\n",
    "            client_data_buffer.append(partite_class_data[class_idx][client_idx])\n",
    "            client_labels_buffer.append(partite_class_labels[class_idx][client_idx])\n",
    "        client_data_buffer = torch.concatenate(client_data_buffer)\n",
    "        client_labels_buffer = torch.concatenate(client_labels_buffer)\n",
    "        \n",
    "        #normalize client data\n",
    "        client_data_buffer = (client_data_buffer - torch.mean(client_data_buffer)) / torch.std(client_data_buffer)\n",
    "        partite_clients_data.append(client_data_buffer.reshape(client_data_buffer.shape[0], -1))\n",
    "        partite_clients_labels.append(client_labels_buffer)\n",
    "    permute_data = torch.randperm(data.shape[0])\n",
    "    data = torch.concatenate(partite_clients_data)[permute_data]\n",
    "    labels = torch.concatenate(partite_clients_labels)[permute_data]\n",
    "    dataset = TensorDataset(data, labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_clients = 64\n",
    "transform = ToTensor()\n",
    "\n",
    "train_dataset = MNIST('./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_dataset.data.shape[0])\n",
    "train_dataset = collect_augment_aggregate(train_loader, num_of_clients)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256)\n",
    "\n",
    "test_dataset = MNIST('./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_dataset.data.shape[0])\n",
    "test_dataset = collect_augment_aggregate(test_loader, num_of_clients)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self, in_channel, hidden_channel, out_channel, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.lin_01 = nn.Linear(in_channel, hidden_channel, bias=False)\n",
    "        self.lin_02 = nn.Linear(hidden_channel, out_channel, bias=False)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.act(self.lin_01(x))\n",
    "        out = self.lin_02(out)\n",
    "        return out\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SimpleNetwork(784, 128, 10).to(device)\n",
    "optim = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3138599395751953\n",
      "accuracy: 0.3732999861240387\n",
      "2.1472933292388916\n",
      "1.9934217929840088\n",
      "1.8154860734939575\n",
      "1.6793084144592285\n",
      "1.5445636510849\n",
      "1.4322694540023804\n",
      "1.241387128829956\n",
      "1.1057384014129639\n",
      "1.045878529548645\n",
      "0.9724445343017578\n",
      "accuracy: 0.802899956703186\n",
      "0.9450538754463196\n",
      "0.8578817844390869\n",
      "0.7757722735404968\n",
      "0.7151757478713989\n",
      "0.6618653535842896\n",
      "0.6178776025772095\n",
      "0.5667965412139893\n",
      "0.6775199174880981\n",
      "0.5910530090332031\n",
      "0.5643151998519897\n",
      "accuracy: 0.8718000054359436\n",
      "0.566311776638031\n",
      "0.4710420072078705\n",
      "0.5314793586730957\n",
      "0.4957160949707031\n",
      "0.5266109108924866\n",
      "0.5244624018669128\n",
      "0.49615031480789185\n",
      "0.3854353427886963\n",
      "0.43622592091560364\n",
      "0.47242966294288635\n",
      "accuracy: 0.8848999738693237\n",
      "0.4319853186607361\n",
      "0.4906245768070221\n",
      "0.3570694625377655\n",
      "0.4795605540275574\n",
      "0.4790980815887451\n",
      "0.3911655843257904\n",
      "0.481953501701355\n",
      "0.37130844593048096\n",
      "0.4266935884952545\n",
      "0.44516521692276\n",
      "accuracy: 0.8956999778747559\n",
      "0.4594241976737976\n",
      "0.3859485685825348\n",
      "0.400579035282135\n",
      "0.3426133990287781\n",
      "0.37199097871780396\n",
      "0.33882054686546326\n",
      "0.46454426646232605\n",
      "0.32899078726768494\n",
      "0.36628082394599915\n",
      "0.3434370160102844\n",
      "accuracy: 0.9041999578475952\n",
      "0.36853522062301636\n",
      "0.2831154763698578\n",
      "0.383937805891037\n",
      "0.49084118008613586\n",
      "0.3336433172225952\n",
      "0.39907699823379517\n",
      "0.33927440643310547\n",
      "0.38778430223464966\n",
      "0.3406161665916443\n",
      "0.324954092502594\n",
      "accuracy: 0.9101999998092651\n",
      "0.43538859486579895\n",
      "0.40577468276023865\n",
      "0.3828931748867035\n",
      "0.2811421751976013\n",
      "0.40811747312545776\n",
      "0.37354469299316406\n",
      "0.4317731261253357\n",
      "0.3909752666950226\n",
      "0.3567025661468506\n",
      "0.3011808395385742\n",
      "accuracy: 0.9108999967575073\n",
      "0.3015296459197998\n",
      "0.2793967127799988\n",
      "0.39901167154312134\n",
      "0.2632744014263153\n",
      "0.3283226191997528\n",
      "0.30530792474746704\n",
      "0.32697755098342896\n",
      "0.22537733614444733\n",
      "0.2919234037399292\n",
      "0.36183109879493713\n",
      "accuracy: 0.9162999987602234\n",
      "0.27878984808921814\n",
      "0.2758205235004425\n",
      "0.28623220324516296\n",
      "0.3204646408557892\n",
      "0.35744568705558777\n",
      "0.27163419127464294\n",
      "0.4165242612361908\n",
      "0.3751718997955322\n",
      "0.33074405789375305\n",
      "0.3486257791519165\n",
      "accuracy: 0.91839998960495\n",
      "0.31896623969078064\n",
      "0.23104944825172424\n",
      "0.27461642026901245\n",
      "0.22397829592227936\n",
      "0.35343438386917114\n",
      "0.2694717347621918\n",
      "0.24569284915924072\n",
      "0.32114720344543457\n",
      "0.33173152804374695\n",
      "0.30325254797935486\n",
      "accuracy: 0.9244999885559082\n",
      "0.34370046854019165\n",
      "0.428752064704895\n",
      "0.2975830137729645\n",
      "0.26339974999427795\n",
      "0.22914762794971466\n",
      "0.3639674782752991\n",
      "0.3217398524284363\n",
      "0.20580987632274628\n",
      "0.27222010493278503\n",
      "0.23840105533599854\n",
      "accuracy: 0.9167999625205994\n",
      "0.2901512682437897\n",
      "0.27472972869873047\n",
      "0.20730771124362946\n",
      "0.23971587419509888\n",
      "0.24814549088478088\n",
      "0.2821143865585327\n",
      "0.253048837184906\n",
      "0.25742533802986145\n",
      "0.2936529815196991\n",
      "0.28046268224716187\n",
      "accuracy: 0.9258999824523926\n",
      "0.27353033423423767\n",
      "0.22734105587005615\n",
      "0.2841678261756897\n",
      "0.2732372283935547\n",
      "0.24016734957695007\n",
      "0.2716315686702728\n",
      "0.27710363268852234\n",
      "0.3756277561187744\n",
      "0.2317749261856079\n",
      "0.2866179943084717\n",
      "accuracy: 0.9162999987602234\n",
      "0.36288902163505554\n",
      "0.33020463585853577\n",
      "0.3611706793308258\n",
      "0.24955293536186218\n",
      "0.27595579624176025\n",
      "0.3045003414154053\n",
      "0.2905656099319458\n",
      "0.24982020258903503\n",
      "0.31483399868011475\n",
      "0.2718132734298706\n",
      "accuracy: 0.9307999610900879\n",
      "0.24149997532367706\n",
      "0.3151761293411255\n",
      "0.2368890941143036\n",
      "0.2734253704547882\n",
      "0.1778530329465866\n",
      "0.2946963906288147\n",
      "0.2585742771625519\n",
      "0.385922908782959\n",
      "0.28064796328544617\n",
      "0.17616795003414154\n",
      "accuracy: 0.9357999563217163\n",
      "0.12503290176391602\n",
      "0.1822284460067749\n",
      "0.21925272047519684\n",
      "0.22521722316741943\n",
      "0.2837265729904175\n",
      "0.28395795822143555\n",
      "0.29633989930152893\n",
      "0.3452230393886566\n",
      "0.2174413502216339\n",
      "0.23913097381591797\n",
      "accuracy: 0.9319999814033508\n",
      "0.3474157750606537\n",
      "0.27316170930862427\n",
      "0.22433137893676758\n",
      "0.299641489982605\n",
      "0.34964701533317566\n",
      "0.3424079716205597\n",
      "0.23876583576202393\n",
      "0.2151728719472885\n",
      "0.284123033285141\n",
      "0.2419220507144928\n",
      "accuracy: 0.9312999844551086\n",
      "0.3028154969215393\n",
      "0.26196005940437317\n",
      "0.2800593376159668\n",
      "0.2713456451892853\n",
      "0.2764343321323395\n",
      "0.3144412636756897\n",
      "0.2786296308040619\n",
      "0.20409278571605682\n",
      "0.25210124254226685\n",
      "0.16575343906879425\n",
      "accuracy: 0.935699999332428\n",
      "0.2568049430847168\n",
      "0.2794850766658783\n",
      "0.17060115933418274\n",
      "0.24791917204856873\n",
      "0.24920502305030823\n",
      "0.23928475379943848\n",
      "0.17583203315734863\n",
      "0.23252461850643158\n",
      "0.22383219003677368\n",
      "0.2136262208223343\n",
      "accuracy: 0.9386999607086182\n",
      "0.32329630851745605\n",
      "0.22301088273525238\n",
      "0.22235292196273804\n",
      "0.20251289010047913\n",
      "0.2503630518913269\n",
      "0.16633281111717224\n",
      "0.23062266409397125\n",
      "0.13313578069210052\n",
      "0.1298847198486328\n",
      "0.19047397375106812\n",
      "accuracy: 0.9368000030517578\n",
      "0.2214159220457077\n",
      "0.2826472520828247\n",
      "0.159944087266922\n",
      "0.25699999928474426\n",
      "0.24206095933914185\n",
      "0.23430821299552917\n",
      "0.2210899144411087\n",
      "0.20347079634666443\n",
      "0.17560340464115143\n",
      "0.21757608652114868\n",
      "accuracy: 0.9422999620437622\n",
      "0.17482039332389832\n",
      "0.18456459045410156\n",
      "0.2329084426164627\n",
      "0.20992925763130188\n",
      "0.14724931120872498\n",
      "0.17396143078804016\n",
      "0.2332509160041809\n",
      "0.20182718336582184\n",
      "0.23400765657424927\n",
      "0.22840942442417145\n",
      "accuracy: 0.9418999552726746\n",
      "0.2266019731760025\n",
      "0.1689014583826065\n",
      "0.2119191586971283\n",
      "0.14269739389419556\n",
      "0.25757038593292236\n",
      "0.21933849155902863\n",
      "0.24600906670093536\n",
      "0.16462785005569458\n",
      "0.19723361730575562\n",
      "0.21936514973640442\n",
      "accuracy: 0.9432999491691589\n",
      "0.3265627324581146\n",
      "0.2691032588481903\n",
      "0.27121251821517944\n",
      "0.2544380724430084\n",
      "accuracy: 0.9431999921798706\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for iter_idx, (data, label) in enumerate(train_loader):\n",
    "    data, label = data.to(device), label.to(device)\n",
    "    optim.zero_grad()\n",
    "    preds = model(data)\n",
    "    loss = criterion(preds, label)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if iter_idx == 0 or (iter_idx % 10) == 0 or iter_idx == (len(train_loader) - 1):\n",
    "        model.eval()\n",
    "        tp_count = 0\n",
    "        val_size = 0\n",
    "        with torch.no_grad():\n",
    "            for val_iter_idx, (val_data, val_label) in enumerate(test_loader):\n",
    "                val_data, val_label = val_data.to(device), val_label.to(device)\n",
    "                val_preds = model(val_data)\n",
    "                val_preds = torch.argmax(val_preds, dim=1)\n",
    "                tp_count += torch.count_nonzero(val_label == val_preds)\n",
    "                val_size += val_data.shape[0]\n",
    "            print('accuracy: {}'.format((tp_count / val_size).item()))\n",
    "        model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

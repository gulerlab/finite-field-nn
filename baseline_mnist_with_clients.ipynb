{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_augment_aggregate(loader, num_of_clients):\n",
    "    data, labels = next(iter(loader))\n",
    "\n",
    "    partite_class_data = []\n",
    "    partite_class_labels = []\n",
    "    for class_idx in range(10):\n",
    "        mask = labels == class_idx\n",
    "        len_mask = torch.count_nonzero(mask)\n",
    "        remainder = len_mask % num_of_clients\n",
    "        split_param = (len_mask // num_of_clients + 1) if remainder != 0 else (len_mask / num_of_clients)\n",
    "        partite_class_data.append(torch.split(data[mask], split_param))\n",
    "        partite_class_labels.append(torch.split(labels[mask], split_param))\n",
    "\n",
    "    partite_clients_data = []\n",
    "    partite_clients_labels = []\n",
    "    for client_idx in range(num_of_clients):\n",
    "        client_data_buffer = []\n",
    "        client_labels_buffer = []\n",
    "        for class_idx in range(10):\n",
    "            client_data_buffer.append(partite_class_data[class_idx][client_idx])\n",
    "            client_labels_buffer.append(partite_class_labels[class_idx][client_idx])\n",
    "        client_data_buffer = torch.concatenate(client_data_buffer)\n",
    "        client_labels_buffer = torch.concatenate(client_labels_buffer)\n",
    "        \n",
    "        #normalize client data\n",
    "        client_data_buffer = (client_data_buffer - torch.mean(client_data_buffer)) / torch.std(client_data_buffer)\n",
    "        partite_clients_data.append(client_data_buffer.reshape(client_data_buffer.shape[0], -1))\n",
    "        partite_clients_labels.append(client_labels_buffer)\n",
    "    permute_data = torch.randperm(data.shape[0])\n",
    "    data = torch.concatenate(partite_clients_data)[permute_data]\n",
    "    labels = torch.concatenate(partite_clients_labels)[permute_data]\n",
    "    dataset = TensorDataset(data, labels)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_clients = 10\n",
    "transform = ToTensor()\n",
    "\n",
    "train_dataset = MNIST('./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_dataset.data.shape[0])\n",
    "train_dataset = collect_augment_aggregate(train_loader, num_of_clients)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256)\n",
    "\n",
    "test_dataset = MNIST('./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_dataset.data.shape[0])\n",
    "test_dataset = collect_augment_aggregate(test_loader, num_of_clients)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self, in_channel, hidden_channel, out_channel, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.lin_01 = nn.Linear(in_channel, hidden_channel, bias=False)\n",
    "        self.lin_02 = nn.Linear(hidden_channel, out_channel, bias=False)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.act(self.lin_01(x))\n",
    "        out = self.lin_02(out)\n",
    "        return out\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SimpleNetwork(784, 128, 10).to(device)\n",
    "optim = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.338310480117798\n",
      "accuracy: 0.2565999925136566\n",
      "2.1451141834259033\n",
      "1.9621187448501587\n",
      "1.8334674835205078\n",
      "1.7286545038223267\n",
      "1.5275076627731323\n",
      "1.3906042575836182\n",
      "1.31075918674469\n",
      "1.1577472686767578\n",
      "1.0699412822723389\n",
      "0.9675514698028564\n",
      "accuracy: 0.7976999878883362\n",
      "0.8969026803970337\n",
      "0.8791893124580383\n",
      "0.7743867635726929\n",
      "0.891302764415741\n",
      "0.7087811231613159\n",
      "0.7663559317588806\n",
      "0.7447514533996582\n",
      "0.6389551758766174\n",
      "0.5624587535858154\n",
      "0.6413402557373047\n",
      "accuracy: 0.8646000027656555\n",
      "0.5258104205131531\n",
      "0.4942413866519928\n",
      "0.5191867351531982\n",
      "0.4634852111339569\n",
      "0.5492941737174988\n",
      "0.42594635486602783\n",
      "0.46482303738594055\n",
      "0.41044968366622925\n",
      "0.4072994589805603\n",
      "0.4142930507659912\n",
      "accuracy: 0.8809999823570251\n",
      "0.4920409917831421\n",
      "0.45844316482543945\n",
      "0.45901286602020264\n",
      "0.44256994128227234\n",
      "0.4438053071498871\n",
      "0.4610747992992401\n",
      "0.3446796238422394\n",
      "0.3227398991584778\n",
      "0.4465421736240387\n",
      "0.39527902007102966\n",
      "accuracy: 0.8892999887466431\n",
      "0.3857544958591461\n",
      "0.3420315086841583\n",
      "0.3558228611946106\n",
      "0.3370327949523926\n",
      "0.3618566393852234\n",
      "0.4089638888835907\n",
      "0.42403900623321533\n",
      "0.3610163629055023\n",
      "0.44018328189849854\n",
      "0.31076234579086304\n",
      "accuracy: 0.9037999510765076\n",
      "0.41262581944465637\n",
      "0.4032350480556488\n",
      "0.3834088444709778\n",
      "0.3849554657936096\n",
      "0.39366039633750916\n",
      "0.3492186665534973\n",
      "0.33937567472457886\n",
      "0.386405885219574\n",
      "0.2580576539039612\n",
      "0.4065892994403839\n",
      "accuracy: 0.9042999744415283\n",
      "0.41203591227531433\n",
      "0.39602339267730713\n",
      "0.29344671964645386\n",
      "0.2841973304748535\n",
      "0.3720758557319641\n",
      "0.2678501307964325\n",
      "0.32468053698539734\n",
      "0.3807908892631531\n",
      "0.34847119450569153\n",
      "0.3645534813404083\n",
      "accuracy: 0.9089999794960022\n",
      "0.402999609708786\n",
      "0.33260995149612427\n",
      "0.27575260400772095\n",
      "0.3436104655265808\n",
      "0.3115287721157074\n",
      "0.2362687587738037\n",
      "0.4305562973022461\n",
      "0.2852247953414917\n",
      "0.3590247929096222\n",
      "0.2925688922405243\n",
      "accuracy: 0.911899983882904\n",
      "0.2771567404270172\n",
      "0.3148185610771179\n",
      "0.2362055778503418\n",
      "0.3369583189487457\n",
      "0.3366469442844391\n",
      "0.23602300882339478\n",
      "0.2777096927165985\n",
      "0.3722115159034729\n",
      "0.24183423817157745\n",
      "0.26604530215263367\n",
      "accuracy: 0.9197999835014343\n",
      "0.31201571226119995\n",
      "0.2725750505924225\n",
      "0.24745823442935944\n",
      "0.1675950437784195\n",
      "0.300400972366333\n",
      "0.32545533776283264\n",
      "0.32217133045196533\n",
      "0.45564600825309753\n",
      "0.2136600911617279\n",
      "0.3314353823661804\n",
      "accuracy: 0.9180999994277954\n",
      "0.3153243362903595\n",
      "0.23463311791419983\n",
      "0.22824159264564514\n",
      "0.2884184718132019\n",
      "0.27735990285873413\n",
      "0.23334404826164246\n",
      "0.290411114692688\n",
      "0.3365376889705658\n",
      "0.26622453331947327\n",
      "0.2585901618003845\n",
      "accuracy: 0.921999990940094\n",
      "0.308016836643219\n",
      "0.2824331820011139\n",
      "0.283671498298645\n",
      "0.35907870531082153\n",
      "0.23549292981624603\n",
      "0.2384391576051712\n",
      "0.2794327437877655\n",
      "0.22081983089447021\n",
      "0.2854244112968445\n",
      "0.18622268736362457\n",
      "accuracy: 0.9233999848365784\n",
      "0.33970555663108826\n",
      "0.2601097524166107\n",
      "0.21579034626483917\n",
      "0.22532720863819122\n",
      "0.25117042660713196\n",
      "0.27434098720550537\n",
      "0.3224847912788391\n",
      "0.30572614073753357\n",
      "0.3361823260784149\n",
      "0.24220424890518188\n",
      "accuracy: 0.9233999848365784\n",
      "0.20293208956718445\n",
      "0.31646397709846497\n",
      "0.37905892729759216\n",
      "0.20454421639442444\n",
      "0.23665955662727356\n",
      "0.24091185629367828\n",
      "0.2735672891139984\n",
      "0.24742241203784943\n",
      "0.33069419860839844\n",
      "0.26772141456604004\n",
      "accuracy: 0.9274999499320984\n",
      "0.3052493929862976\n",
      "0.3511265516281128\n",
      "0.28226715326309204\n",
      "0.24491098523139954\n",
      "0.2889648675918579\n",
      "0.3722112476825714\n",
      "0.23079536855220795\n",
      "0.241899311542511\n",
      "0.1747485250234604\n",
      "0.2199106216430664\n",
      "accuracy: 0.9294999837875366\n",
      "0.29935920238494873\n",
      "0.22412574291229248\n",
      "0.2693643569946289\n",
      "0.23171594738960266\n",
      "0.2556943893432617\n",
      "0.314316987991333\n",
      "0.28626057505607605\n",
      "0.2593387961387634\n",
      "0.2461150884628296\n",
      "0.26892703771591187\n",
      "accuracy: 0.9319999814033508\n",
      "0.3632045388221741\n",
      "0.21120181679725647\n",
      "0.2320641726255417\n",
      "0.26127392053604126\n",
      "0.2113610953092575\n",
      "0.314167320728302\n",
      "0.2591578960418701\n",
      "0.34999293088912964\n",
      "0.18011474609375\n",
      "0.20212793350219727\n",
      "accuracy: 0.9309999942779541\n",
      "0.22402627766132355\n",
      "0.26388782262802124\n",
      "0.26740339398384094\n",
      "0.179433211684227\n",
      "0.2051447182893753\n",
      "0.27012181282043457\n",
      "0.25364866852760315\n",
      "0.24998332560062408\n",
      "0.22769257426261902\n",
      "0.23650556802749634\n",
      "accuracy: 0.9327999949455261\n",
      "0.23573113977909088\n",
      "0.20447272062301636\n",
      "0.2552897036075592\n",
      "0.24623139202594757\n",
      "0.309224396944046\n",
      "0.242947518825531\n",
      "0.22773733735084534\n",
      "0.30353909730911255\n",
      "0.24816448986530304\n",
      "0.2505357563495636\n",
      "accuracy: 0.9362999796867371\n",
      "0.2201310247182846\n",
      "0.33136340975761414\n",
      "0.15786463022232056\n",
      "0.2858606278896332\n",
      "0.2204040288925171\n",
      "0.24169285595417023\n",
      "0.18350493907928467\n",
      "0.27372583746910095\n",
      "0.32275986671447754\n",
      "0.15777623653411865\n",
      "accuracy: 0.9375\n",
      "0.23021870851516724\n",
      "0.29780271649360657\n",
      "0.13894200325012207\n",
      "0.28926166892051697\n",
      "0.22077228128910065\n",
      "0.18649126589298248\n",
      "0.22297433018684387\n",
      "0.2153777778148651\n",
      "0.2887553870677948\n",
      "0.21135152876377106\n",
      "accuracy: 0.9394999742507935\n",
      "0.17630290985107422\n",
      "0.20831267535686493\n",
      "0.17861832678318024\n",
      "0.18446215987205505\n",
      "0.18063731491565704\n",
      "0.2631632685661316\n",
      "0.15391087532043457\n",
      "0.2820659279823303\n",
      "0.2568820118904114\n",
      "0.20416614413261414\n",
      "accuracy: 0.939300000667572\n",
      "0.1555517166852951\n",
      "0.17176029086112976\n",
      "0.1370767056941986\n",
      "0.2021389901638031\n",
      "0.2795694172382355\n",
      "0.20672184228897095\n",
      "0.22948172688484192\n",
      "0.22980952262878418\n",
      "0.22654753923416138\n",
      "0.1682053655385971\n",
      "accuracy: 0.9422000050544739\n",
      "0.2535901367664337\n",
      "0.20710711181163788\n",
      "0.17824535071849823\n",
      "0.2903915047645569\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for iter_idx, (data, label) in enumerate(train_loader):\n",
    "    data, label = data.to(device), label.to(device)\n",
    "    optim.zero_grad()\n",
    "    preds = model(data)\n",
    "    loss = criterion(preds, label)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if iter_idx == 0 or (iter_idx % 10) == 0:\n",
    "        model.eval()\n",
    "        tp_count = 0\n",
    "        val_size = 0\n",
    "        with torch.no_grad():\n",
    "            for val_iter_idx, (val_data, val_label) in enumerate(test_loader):\n",
    "                val_data, val_label = val_data.to(device), val_label.to(device)\n",
    "                val_preds = model(val_data)\n",
    "                val_preds = torch.argmax(val_preds, dim=1)\n",
    "                tp_count += torch.count_nonzero(val_label == val_preds)\n",
    "                val_size += val_data.shape[0]\n",
    "            print('accuracy: {}'.format((tp_count / val_size).item()))\n",
    "        model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from utils_numpy import create_batch_data\n",
    "from torchvision.models import VGG16_BN_Weights, vgg16_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_augment_aggregate_data(dataset, dataloader, num_of_clients, num_of_classes):\n",
    "    data, labels = next(iter(dataloader))\n",
    "    data, labels = data.numpy(), labels.numpy()\n",
    "    targets = dataset.targets\n",
    "    if not isinstance(targets, np.ndarray):\n",
    "        targets = np.asarray(targets)\n",
    "\n",
    "    different_classes_data = []\n",
    "    different_classes_labels = []\n",
    "    for class_id in range(num_of_classes):\n",
    "        different_classes_data.append(np.array_split(data[targets == class_id], num_of_clients))\n",
    "        different_classes_labels.append(np.array_split(labels[targets == class_id], num_of_clients))\n",
    "    \n",
    "    client_data = []\n",
    "    client_labels = []\n",
    "    for client_idx in range(num_of_clients):\n",
    "        client_data_buffer = []\n",
    "        client_labels_buffer = []\n",
    "        for class_idx in range(num_of_classes):\n",
    "            client_data_buffer.append(different_classes_data[class_idx][client_idx])\n",
    "            client_labels_buffer.append(different_classes_labels[class_idx][client_idx])\n",
    "\n",
    "        client_data_buffer = np.concatenate(client_data_buffer)\n",
    "        for channel_idx in range(client_data_buffer.shape[1]):\n",
    "            client_data_buffer[:, channel_idx, :, :] = (client_data_buffer[:, channel_idx, :, :] - np.mean(client_data_buffer[:, channel_idx, :, :])) / np.std(client_data_buffer[:, channel_idx, :, :])\n",
    "\n",
    "        client_data.append(client_data_buffer)\n",
    "        client_labels.append(np.concatenate(client_labels_buffer))\n",
    "    aggregated_data = np.concatenate(client_data)\n",
    "    aggregated_labels = np.concatenate(client_labels)\n",
    "    randomize = np.random.permutation(aggregated_data.shape[0])\n",
    "    return aggregated_data[randomize], aggregated_labels[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data_apply_vgg_cifar10(num_of_clients: int = 64):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    transform = Compose([\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # load data\n",
    "    train_dataset = CIFAR10('./data', train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=train_dataset.data.shape[0], shuffle=False)\n",
    "    test_dataset = CIFAR10('./data', train=False, transform=transform, download=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_dataset.data.shape[0], shuffle=False)\n",
    "\n",
    "\n",
    "    all_train_data, all_train_labels = collect_augment_aggregate_data(train_dataset, train_loader, num_of_clients, 10)\n",
    "    all_test_data, all_test_labels = collect_augment_aggregate_data(test_dataset, test_loader, num_of_clients, 10)\n",
    "    all_train_data, all_train_labels, all_test_data, all_test_labels = create_batch_data(all_train_data, all_train_labels, all_test_data, all_test_labels, 256)\n",
    "\n",
    "    vgg_backbone = vgg16_bn(weights=VGG16_BN_Weights.DEFAULT).eval()\n",
    "    vgg_backbone = torch.nn.Sequential(*(list(vgg_backbone.children())[:-1])).to(device)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_data_all, train_label_all, test_data_all, test_label_all = [], [], [], []\n",
    "        for train_data, train_label in zip(all_train_data, all_train_labels):\n",
    "            train_data = torch.tensor(train_data)\n",
    "            train_data = train_data.to(device)\n",
    "            train_data = vgg_backbone(train_data).reshape(train_data.size(0), -1).to('cpu').numpy()\n",
    "\n",
    "            train_data_all.append(train_data)\n",
    "            train_label_all.append(train_label)\n",
    "\n",
    "        for test_data, test_label in zip(all_test_data, all_test_labels):\n",
    "            test_label_all.append(test_label)\n",
    "            test_data = torch.tensor(test_data)\n",
    "            test_data = test_data.to(device)\n",
    "            test_data = vgg_backbone(test_data).reshape(test_data.size(0), -1).to('cpu').numpy()\n",
    "            test_data_all.append(test_data)\n",
    "\n",
    "    train_data_all, train_label_all = np.concatenate(train_data_all, axis=0), np.concatenate(train_label_all, axis=0)\n",
    "    test_data_all, test_label_all = np.concatenate(test_data_all, axis=0), np.concatenate(test_label_all, axis=0)\n",
    "    train_data_all, train_label_all = torch.tensor(train_data_all), torch.tensor(train_label_all)\n",
    "    test_data_all, test_label_all = torch.tensor(test_data_all), torch.tensor(test_label_all)\n",
    "    train_dataset = TensorDataset(train_data_all, train_label_all)\n",
    "    test_dataset = TensorDataset(test_data_all, test_label_all)\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = load_all_data_apply_vgg_cifar10()\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self, in_channel, hidden_channel, out_channel, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.lin_01 = nn.Linear(in_channel, hidden_channel, bias=False)\n",
    "        self.lin_02 = nn.Linear(hidden_channel, out_channel, bias=False)\n",
    "        self.act = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.act(self.lin_01(x))\n",
    "        out = self.lin_02(out)\n",
    "        return out\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SimpleNetwork(25088, 128, 10).to(device)\n",
    "optim = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3137998580932617\n",
      "epoch: 1, accuracy: 0.4414999783039093\n",
      "1.7017310857772827\n",
      "2.028775691986084\n",
      "2.1806061267852783\n",
      "1.674379825592041\n",
      "1.463227391242981\n",
      "1.2385197877883911\n",
      "1.1776175498962402\n",
      "1.227717399597168\n",
      "1.2208075523376465\n",
      "1.1735552549362183\n",
      "epoch: 11, accuracy: 0.609499990940094\n",
      "1.1273291110992432\n",
      "1.064523696899414\n",
      "1.0056588649749756\n",
      "0.9846765398979187\n",
      "0.9945262670516968\n",
      "1.0076960325241089\n",
      "1.0059475898742676\n",
      "0.988359272480011\n",
      "0.9625404477119446\n",
      "0.9365968704223633\n",
      "epoch: 21, accuracy: 0.6699999570846558\n",
      "0.916249692440033\n",
      "0.9046121835708618\n",
      "0.9003856182098389\n",
      "0.8983786106109619\n",
      "0.8948873281478882\n",
      "0.889539897441864\n",
      "0.8823285698890686\n",
      "0.8728592991828918\n",
      "0.8618923425674438\n",
      "0.8518404960632324\n",
      "epoch: 31, accuracy: 0.6972999572753906\n",
      "0.8449824452400208\n",
      "0.8414435386657715\n",
      "0.839088499546051\n",
      "0.8353558778762817\n",
      "0.8292747735977173\n",
      "0.8221278190612793\n",
      "0.8155743479728699\n",
      "0.8099056482315063\n",
      "0.8055111169815063\n",
      "0.8026041984558105\n",
      "epoch: 41, accuracy: 0.7028999924659729\n",
      "0.7997113466262817\n",
      "0.7954975962638855\n",
      "0.7905491590499878\n",
      "0.786160409450531\n",
      "0.7824762463569641\n",
      "0.7790855765342712\n",
      "0.7757506966590881\n",
      "0.7723117470741272\n",
      "0.7688578367233276\n",
      "0.7654147744178772\n",
      "epoch: 51, accuracy: 0.7113999724388123\n",
      "0.7620088458061218\n",
      "0.7588265538215637\n",
      "0.756023108959198\n",
      "0.7533379793167114\n",
      "0.7504462003707886\n",
      "0.7474444508552551\n",
      "0.7445509433746338\n",
      "0.7418148517608643\n",
      "0.7391796112060547\n",
      "0.736624538898468\n",
      "epoch: 61, accuracy: 0.7166000008583069\n",
      "0.7340920567512512\n",
      "0.7314966917037964\n",
      "0.7288956046104431\n",
      "0.7264140844345093\n",
      "0.7240291237831116\n",
      "0.7216827869415283\n",
      "0.719306468963623\n",
      "0.7168745398521423\n",
      "0.7144824862480164\n",
      "0.7122270464897156\n",
      "epoch: 71, accuracy: 0.7198999524116516\n",
      "0.7100333571434021\n",
      "0.7078088521957397\n",
      "0.7055502533912659\n",
      "0.703315019607544\n",
      "0.7011429667472839\n",
      "0.6989957094192505\n",
      "0.6968507170677185\n",
      "0.6947175860404968\n",
      "0.6926023364067078\n",
      "0.6905033588409424\n",
      "epoch: 81, accuracy: 0.7231999635696411\n",
      "0.6884313225746155\n",
      "0.6863630414009094\n",
      "0.6842862367630005\n",
      "0.6822260022163391\n",
      "0.6801949143409729\n",
      "0.6781783699989319\n",
      "0.676164448261261\n",
      "0.6741384267807007\n",
      "0.6721359491348267\n",
      "0.6701575517654419\n",
      "epoch: 91, accuracy: 0.724399983882904\n",
      "0.6681856513023376\n",
      "0.6662192940711975\n",
      "0.6642548441886902\n",
      "0.6622929573059082\n",
      "0.6603343486785889\n",
      "0.6583837270736694\n",
      "0.656444787979126\n",
      "0.6545106172561646\n",
      "0.652574896812439\n",
      "0.6506624817848206\n",
      "epoch: 101, accuracy: 0.7236999869346619\n",
      "0.6487489342689514\n",
      "0.6468562483787537\n",
      "0.6449796557426453\n",
      "0.6430743932723999\n",
      "0.6411880254745483\n",
      "0.6392555832862854\n",
      "0.6373795866966248\n",
      "0.6355307698249817\n",
      "0.6336235404014587\n",
      "0.6317456960678101\n",
      "epoch: 111, accuracy: 0.7245000004768372\n",
      "0.6299296617507935\n",
      "0.6280770897865295\n",
      "0.6262041926383972\n",
      "0.624352216720581\n",
      "0.6225196719169617\n",
      "0.6207131743431091\n",
      "0.6189165711402893\n",
      "0.6171237230300903\n",
      "0.615272045135498\n",
      "0.6134593486785889\n",
      "epoch: 121, accuracy: 0.7239999771118164\n",
      "0.6116834282875061\n",
      "0.6099560856819153\n",
      "0.6082203984260559\n",
      "0.6063477396965027\n",
      "0.6046139597892761\n",
      "0.6029934883117676\n",
      "0.6011000871658325\n",
      "0.599380373954773\n",
      "0.5977266430854797\n",
      "0.5958554744720459\n",
      "epoch: 131, accuracy: 0.7228999733924866\n",
      "0.5943495631217957\n",
      "0.5926275253295898\n",
      "0.5908164978027344\n",
      "0.5894535779953003\n",
      "0.5873638987541199\n",
      "0.5857928395271301\n",
      "0.5839523077011108\n",
      "0.5822340846061707\n",
      "0.5806481838226318\n",
      "0.5789023041725159\n",
      "epoch: 141, accuracy: 0.7218999862670898\n",
      "0.5772703289985657\n",
      "0.5754214525222778\n",
      "0.5738481879234314\n",
      "0.5721861124038696\n",
      "0.5705439448356628\n",
      "0.5688649415969849\n",
      "0.5671430230140686\n",
      "0.5655935406684875\n",
      "0.5639654397964478\n",
      "0.5622863173484802\n",
      "epoch: 151, accuracy: 0.7213999629020691\n",
      "0.5606316924095154\n",
      "0.5589884519577026\n",
      "0.5573350787162781\n",
      "0.5558046698570251\n",
      "0.5541096925735474\n",
      "0.5524681806564331\n",
      "0.5508425235748291\n",
      "0.5493379235267639\n",
      "0.5479059219360352\n",
      "0.5463389158248901\n",
      "epoch: 161, accuracy: 0.7213000059127808\n",
      "0.5450199246406555\n",
      "0.5433728694915771\n",
      "0.5420380234718323\n",
      "0.5399026274681091\n",
      "0.5380977988243103\n",
      "0.5366518497467041\n",
      "0.5352104306221008\n",
      "0.5339007377624512\n",
      "0.5320773124694824\n",
      "0.5302425622940063\n",
      "epoch: 171, accuracy: 0.7196999788284302\n",
      "0.5287404656410217\n",
      "0.527381181716919\n",
      "0.5258574485778809\n",
      "0.524168074131012\n",
      "0.5225663781166077\n",
      "0.5208195447921753\n",
      "0.5194808840751648\n",
      "0.5182477235794067\n",
      "0.516471803188324\n",
      "0.5151079297065735\n",
      "epoch: 181, accuracy: 0.7200999855995178\n",
      "0.5138559937477112\n",
      "0.5125243067741394\n",
      "0.5115416049957275\n",
      "0.5092166662216187\n",
      "0.5074310898780823\n",
      "0.5059412121772766\n",
      "0.5045795440673828\n",
      "0.5032252669334412\n",
      "0.5017637014389038\n",
      "0.5002465844154358\n",
      "epoch: 191, accuracy: 0.7159000039100647\n",
      "0.4990637004375458\n",
      "0.4974701702594757\n",
      "0.495903879404068\n",
      "0.494135320186615\n",
      "0.4926775097846985\n",
      "epoch: 196, accuracy: 0.7170999646186829\n",
      "0.491120308637619\n",
      "0.4895989000797272\n",
      "0.48810821771621704\n",
      "0.48664844036102295\n",
      "0.4851416051387787\n",
      "epoch: 201, accuracy: 0.7166999578475952\n",
      "0.48386242985725403\n",
      "0.4826424717903137\n",
      "0.48140692710876465\n",
      "0.4808015525341034\n",
      "0.4801553785800934\n",
      "0.47950994968414307\n",
      "0.47733867168426514\n",
      "0.4748517870903015\n",
      "0.4729764461517334\n",
      "0.4718901515007019\n",
      "epoch: 211, accuracy: 0.7148000001907349\n",
      "0.47131067514419556\n",
      "0.47055745124816895\n",
      "0.4688999354839325\n",
      "0.46661725640296936\n",
      "0.4649185240268707\n",
      "0.46410584449768066\n",
      "0.46362727880477905\n",
      "0.4623960852622986\n",
      "0.4601958692073822\n",
      "0.45813092589378357\n",
      "epoch: 221, accuracy: 0.714199960231781\n",
      "0.4567795693874359\n",
      "0.4559595584869385\n",
      "0.4551759660243988\n",
      "0.4538179337978363\n",
      "0.452208936214447\n",
      "0.45007210969924927\n",
      "0.44890081882476807\n",
      "0.44815748929977417\n",
      "0.4474869966506958\n",
      "0.4462127983570099\n",
      "epoch: 231, accuracy: 0.7131999731063843\n",
      "0.44443488121032715\n",
      "0.4427117109298706\n",
      "0.44127175211906433\n",
      "0.44013866782188416\n",
      "0.43935754895210266\n",
      "0.43867215514183044\n",
      "0.4372970163822174\n",
      "0.4354964792728424\n",
      "0.43382030725479126\n",
      "0.4325118660926819\n",
      "epoch: 241, accuracy: 0.7109000086784363\n",
      "0.43114393949508667\n",
      "0.4300372302532196\n",
      "0.4287590980529785\n",
      "0.4278976023197174\n",
      "0.4270044267177582\n",
      "0.4260748028755188\n",
      "0.4250854551792145\n",
      "0.4240272343158722\n",
      "0.4225049316883087\n",
      "0.4208829998970032\n",
      "epoch: 251, accuracy: 0.7092999815940857\n",
      "0.4194222390651703\n",
      "0.41834962368011475\n",
      "0.41682663559913635\n",
      "0.4156677722930908\n",
      "0.41457414627075195\n",
      "0.4135144054889679\n",
      "0.41227027773857117\n",
      "0.4115442633628845\n",
      "0.41037672758102417\n",
      "0.40970468521118164\n",
      "epoch: 261, accuracy: 0.7091999650001526\n",
      "0.40984469652175903\n",
      "0.40910911560058594\n",
      "0.4082322120666504\n",
      "0.40588393807411194\n",
      "0.40357252955436707\n",
      "0.40259408950805664\n",
      "0.40147796273231506\n",
      "0.40058135986328125\n",
      "0.3999408483505249\n",
      "0.3986422121524811\n",
      "epoch: 271, accuracy: 0.7069999575614929\n",
      "0.3976823687553406\n",
      "0.39705145359039307\n",
      "0.3950493037700653\n",
      "0.3934115171432495\n",
      "0.39202407002449036\n",
      "0.39125561714172363\n",
      "0.3901994824409485\n",
      "0.3894210159778595\n",
      "0.3878183662891388\n",
      "0.3868980407714844\n",
      "epoch: 281, accuracy: 0.7056999802589417\n",
      "0.38587436079978943\n",
      "0.38530632853507996\n",
      "0.3842310607433319\n",
      "0.38316452503204346\n",
      "0.3820068836212158\n",
      "0.38079333305358887\n",
      "0.3801170289516449\n",
      "0.3790835440158844\n",
      "0.37804797291755676\n",
      "0.37639278173446655\n",
      "epoch: 291, accuracy: 0.7050999999046326\n",
      "0.37519094347953796\n",
      "0.37399932742118835\n",
      "0.3728845417499542\n",
      "0.3715622127056122\n",
      "0.37065479159355164\n",
      "0.3695247769355774\n",
      "0.36851152777671814\n",
      "0.36772212386131287\n",
      "0.36735260486602783\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    model.train()\n",
    "    for iter_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optim.zero_grad()\n",
    "        preds = model(data)\n",
    "        loss = criterion(preds, label)\n",
    "        print(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if epoch == 0 or (epoch % 10) == 0 or epoch == 195:\n",
    "            model.eval()\n",
    "            tp_count = 0\n",
    "            val_size = 0\n",
    "            with torch.no_grad():\n",
    "                for val_iter_idx, (val_data, val_label) in enumerate(test_loader):\n",
    "                    val_data, val_label = val_data.to(device), val_label.to(device)\n",
    "                    val_preds = model(val_data)\n",
    "                    val_preds = torch.argmax(val_preds, dim=1)\n",
    "                    tp_count += torch.count_nonzero(val_label == val_preds)\n",
    "                    val_size += val_data.shape[0]\n",
    "                print('epoch: {}, accuracy: {}'.format(epoch + 1, (tp_count / val_size).item()))\n",
    "            model.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

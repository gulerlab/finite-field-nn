{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-23T20:56:02.514094508Z",
     "start_time": "2023-06-23T20:56:01.861153623Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_all_data_mnist, load_all_data_cifar10, load_all_data_fashion_mnist, load_all_data_apply_vgg_cifar10\n",
    "from utils import create_batch_data\n",
    "import modules\n",
    "import layers\n",
    "from criterions import IntegerMSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 5\n",
    "PRINT = 10\n",
    "FLATTEN = False\n",
    "# 0, MNIST; 1, FashionMNIST; 2, CIFAR10; 3, VGG-CIFAR10\n",
    "DATASET_MODE = 2\n",
    "\n",
    "QUANTIZATION_INPUT = 8\n",
    "QUANTIZATION_WEIGHT = 8\n",
    "QUANTIZATION_BATCH_SIZE = 8\n",
    "LR = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T20:56:02.778096350Z",
     "start_time": "2023-06-23T20:56:02.776861168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# data fetching\n",
    "load_path = '../../data'\n",
    "if DATASET_MODE == 0:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_mnist(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 1:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_fashion_mnist(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 2:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_cifar10(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 3:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_apply_vgg_cifar10(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, flatten=FLATTEN)\n",
    "else:\n",
    "    train_data, train_label, test_data, test_label = None, None, None, None\n",
    "train_data, train_label, test_data, test_label = create_batch_data(train_data, train_label, test_data, test_label, BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T20:56:10.058274609Z",
     "start_time": "2023-06-23T20:56:03.586471704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_arr = [\n",
    "    layers.IntegerPiNetSecondOrderConvLayer(3, 6, (9, 9), QUANTIZATION_WEIGHT, first_layer=True, quantization_input=QUANTIZATION_INPUT),\n",
    "    layers.IntegerPiNetSecondOrderConvLayer(6, 6, (5, 5), QUANTIZATION_WEIGHT),\n",
    "    modules.Flatten(),\n",
    "    layers.IntegerPiNetSecondOrderLinearLayer(2400, 128, QUANTIZATION_WEIGHT),\n",
    "    layers.IntegerLinearLayer(128, 10, QUANTIZATION_WEIGHT)\n",
    "]\n",
    "\n",
    "model = modules.Network(model_arr)\n",
    "criterion = IntegerMSELoss(QUANTIZATION_WEIGHT, QUANTIZATION_BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T20:56:10.892856170Z",
     "start_time": "2023-06-23T20:56:10.886930050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    tot_loss = 0\n",
    "    for train_idx, (train_data_batch, train_label_batch) in enumerate(zip(train_data, train_label)):\n",
    "        # train\n",
    "        preds = model.forward(train_data_batch)\n",
    "\n",
    "        loss = criterion.forward(preds, train_label_batch)\n",
    "        tot_loss += loss\n",
    "        propagated_error = criterion.error_derivative()\n",
    "\n",
    "        model.backprop(propagated_error)\n",
    "        model.optimize(LR)\n",
    "        if train_idx == 0 or (train_idx + 1) % PRINT == 0:\n",
    "            tot_acc = 0\n",
    "            tot_sample = 0\n",
    "            for train_acc_idx, (test_data_batch, test_label_batch) in enumerate(zip(test_data, test_label)):\n",
    "                # train accuracy\n",
    "                preds = model.forward(test_data_batch)\n",
    "                pred_args = np.argmax(preds, axis=1)\n",
    "\n",
    "                tot_acc += np.count_nonzero(pred_args == test_label_batch)\n",
    "                tot_sample += test_data_batch.shape[0]\n",
    "            accuracy = tot_acc / tot_sample\n",
    "            if train_idx != 0:\n",
    "                tot_loss = tot_loss / PRINT\n",
    "            print('epoch: {}, idx: {}, accuracy: {}, loss: {}'.format(epoch + 1, train_idx + 1, accuracy, tot_loss))\n",
    "            tot_loss = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-21T00:25:04.062867001Z",
     "start_time": "2023-06-21T00:25:03.415234009Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from networks import FiniteFieldPiNetNetworkLinear, FiniteFieldPiNetNetworkLeNet, FiniteFieldPiNetNetworkLeNetCIFAR10\n",
    "from criterions import FiniteFieldMSELoss\n",
    "from datasets import load_all_data_mnist, load_all_data_cifar10\n",
    "from utils import create_batch_data, to_real_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCH = 1\n",
    "LR = 8\n",
    "PRINT = 10\n",
    "MODE = 3\n",
    "PRIME = 2**26 - 5\n",
    "QUANTIZATION_WEIGHT = 8\n",
    "QUANTIZATION_INPUT = 8\n",
    "QUANTIZATION_BATCH_SIZE = 7"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T00:25:08.179348802Z",
     "start_time": "2023-06-21T00:25:08.175208195Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if MODE == 1:\n",
    "    model = FiniteFieldPiNetNetworkLinear(QUANTIZATION_WEIGHT, PRIME, QUANTIZATION_INPUT)\n",
    "    flatten = True\n",
    "elif MODE == 2:\n",
    "    model = FiniteFieldPiNetNetworkLeNet(QUANTIZATION_WEIGHT, PRIME, QUANTIZATION_INPUT)\n",
    "    flatten = False\n",
    "elif MODE == 3:\n",
    "    model = FiniteFieldPiNetNetworkLeNetCIFAR10(QUANTIZATION_WEIGHT, PRIME, QUANTIZATION_INPUT)\n",
    "    flatten = False\n",
    "else:\n",
    "    model = None\n",
    "    flatten = True\n",
    "criterion = FiniteFieldMSELoss(PRIME, QUANTIZATION_WEIGHT, QUANTIZATION_BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T00:25:11.252659979Z",
     "start_time": "2023-06-21T00:25:11.169206139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# data fetching\n",
    "load_path = '../../data'\n",
    "train_data, train_label, test_data, test_label = load_all_data_cifar10(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, flatten=flatten)\n",
    "train_data, train_label, test_data, test_label = create_batch_data(train_data, train_label, test_data, test_label, BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T00:25:24.367915035Z",
     "start_time": "2023-06-21T00:25:17.261287833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    tot_loss = 0\n",
    "    for train_idx, (train_data_batch, train_label_batch) in enumerate(zip(train_data, train_label)):\n",
    "        # train\n",
    "        preds = model.forward(train_data_batch)\n",
    "\n",
    "        loss = criterion.forward(preds, train_label_batch)\n",
    "        tot_loss += loss\n",
    "        propagated_error = criterion.error_derivative()\n",
    "\n",
    "        model.backprop(propagated_error)\n",
    "        model.optimize(LR)\n",
    "        print('idx: {}, loss: {}'.format(train_idx + 1, loss))\n",
    "        if (train_idx + 1) % PRINT == 0:\n",
    "            print('epoch: {}, idx: {}, loss: {}'.format(epoch + 1, train_idx + 1, tot_loss / PRINT))\n",
    "\n",
    "        # if (train_idx + 1) % PRINT == 0:\n",
    "        #     tot_acc = 0\n",
    "        #     tot_sample = 0\n",
    "        #     for train_acc_idx, (test_data_batch, test_label_batch) in enumerate(zip(test_data, test_label)):\n",
    "        #         # train accuracy\n",
    "        #         preds = model.forward(test_data_batch)\n",
    "        #         real_preds = to_real_domain(preds, QUANTIZATION_WEIGHT, PRIME)\n",
    "        #         pred_args = np.argmax(real_preds, axis=1)\n",
    "        #\n",
    "        #         tot_acc += np.count_nonzero(pred_args == test_label_batch)\n",
    "        #         tot_sample += test_data_batch.shape[0]\n",
    "        #\n",
    "        #     accuracy = tot_acc / tot_sample\n",
    "        #     if train_idx != 0:\n",
    "        #         tot_loss = tot_loss / PRINT\n",
    "        #     print('epoch: {}, idx: {}, accuracy: {}, loss: {}'.format(epoch + 1, train_idx + 1, accuracy, tot_loss))\n",
    "        #     tot_loss = 0"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-21T00:25:25.837459711Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

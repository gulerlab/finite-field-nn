{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:16:59.699120573Z",
     "start_time": "2023-06-22T22:16:58.633620451Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from networks import FiniteFieldPiNetNetworkLinear, FiniteFieldPiNetNetworkLeNet, FiniteFieldPiNetNetworkLeNetCIFAR10, FiniteFieldPiNetNetworkDebug\n",
    "from criterions import FiniteFieldMSELoss\n",
    "from datasets import load_all_data_mnist, load_all_data_cifar10\n",
    "from utils import create_batch_data, to_real_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 1\n",
    "LR = 7\n",
    "PRINT = 10\n",
    "MODE = 'debug'\n",
    "PRIME = 2**26 - 5\n",
    "QUANTIZATION_WEIGHT = 8\n",
    "QUANTIZATION_INPUT = 8\n",
    "QUANTIZATION_BATCH_SIZE = 8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T22:17:00.697859296Z",
     "start_time": "2023-06-22T22:17:00.696318679Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if MODE == 1:\n",
    "    model = FiniteFieldPiNetNetworkLinear(QUANTIZATION_WEIGHT, PRIME, QUANTIZATION_INPUT)\n",
    "    flatten = True\n",
    "elif MODE == 2:\n",
    "    model = FiniteFieldPiNetNetworkLeNet(QUANTIZATION_WEIGHT, PRIME, QUANTIZATION_INPUT)\n",
    "    flatten = False\n",
    "elif MODE == 3:\n",
    "    model = FiniteFieldPiNetNetworkLeNetCIFAR10(QUANTIZATION_WEIGHT, PRIME, QUANTIZATION_INPUT)\n",
    "    flatten = False\n",
    "elif MODE == 'debug':\n",
    "    model = FiniteFieldPiNetNetworkDebug(QUANTIZATION_WEIGHT, PRIME, QUANTIZATION_INPUT)\n",
    "    flatten = False\n",
    "else:\n",
    "    model = None\n",
    "    flatten = True\n",
    "criterion = FiniteFieldMSELoss(PRIME, QUANTIZATION_WEIGHT, QUANTIZATION_BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T04:14:33.261212601Z",
     "start_time": "2023-06-22T04:14:33.234422195Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# data fetching\n",
    "load_path = '../../data'\n",
    "train_data, train_label, test_data, test_label = load_all_data_mnist(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, flatten=flatten)\n",
    "train_data, train_label, test_data, test_label = create_batch_data(train_data, train_label, test_data, test_label, BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T04:14:39.062417296Z",
     "start_time": "2023-06-22T04:14:34.548524123Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 1, loss: 2.8752511739730835\n",
      "idx: 2, loss: 1.820149004459381\n",
      "idx: 3, loss: 3.1006760597229\n",
      "idx: 4, loss: 2.352128386497498\n",
      "idx: 5, loss: 1.8502511978149414\n",
      "idx: 6, loss: 0.9645739197731018\n",
      "idx: 7, loss: 0.8610182404518127\n",
      "idx: 8, loss: 0.9194228649139405\n",
      "idx: 9, loss: 0.805298924446106\n",
      "idx: 10, loss: 0.7365047931671143\n",
      "epoch: 1, idx: 10, loss: 1.6285274565219878\n",
      "epoch: 1, idx: 10, accuracy: 0.5838, loss: 0.0\n",
      "idx: 11, loss: 0.7790211439132689\n",
      "idx: 12, loss: 0.8088868856430053\n",
      "idx: 13, loss: 0.7293991446495056\n",
      "idx: 14, loss: 0.811723232269287\n",
      "idx: 15, loss: 0.7457399964332582\n",
      "idx: 16, loss: 0.6620576977729797\n",
      "idx: 17, loss: 0.6312770843505859\n",
      "idx: 18, loss: 0.6187778115272522\n",
      "idx: 19, loss: 0.6908708214759827\n",
      "idx: 20, loss: 0.615646719932556\n",
      "epoch: 1, idx: 20, loss: 0.7093400537967682\n",
      "epoch: 1, idx: 20, accuracy: 0.7135, loss: 0.0\n",
      "idx: 21, loss: 0.598652720451355\n",
      "idx: 22, loss: 0.5760615468025208\n",
      "idx: 23, loss: 0.5898118615150453\n",
      "idx: 24, loss: 0.6099125146865845\n",
      "idx: 25, loss: 0.6280621886253356\n",
      "idx: 26, loss: 0.5589463710784912\n",
      "idx: 27, loss: 0.6182720065116882\n",
      "idx: 28, loss: 0.6071428060531616\n",
      "idx: 29, loss: 0.6685732007026672\n",
      "idx: 30, loss: 0.5880357623100281\n",
      "epoch: 1, idx: 30, loss: 0.6043470978736878\n",
      "epoch: 1, idx: 30, accuracy: 0.7611, loss: 0.0\n",
      "idx: 31, loss: 0.6079101562500001\n",
      "idx: 32, loss: 0.6081599593162536\n",
      "idx: 33, loss: 0.6242583990097046\n",
      "idx: 34, loss: 0.5982872843742371\n",
      "idx: 35, loss: 0.6302079558372496\n",
      "idx: 36, loss: 0.541654646396637\n",
      "idx: 37, loss: 0.5927634835243226\n",
      "idx: 38, loss: 0.5750876069068909\n",
      "idx: 39, loss: 0.5508901476860046\n",
      "idx: 40, loss: 0.5760064721107483\n",
      "epoch: 1, idx: 40, loss: 0.5905226111412049\n",
      "epoch: 1, idx: 40, accuracy: 0.7693, loss: 0.0\n",
      "idx: 41, loss: 0.5569904446601868\n",
      "idx: 42, loss: 0.5246884226799011\n",
      "idx: 43, loss: 0.5191954374313354\n",
      "idx: 44, loss: 0.5297201871871948\n",
      "idx: 45, loss: 0.48127508163452154\n",
      "idx: 46, loss: 0.5550262928009033\n",
      "idx: 47, loss: 0.5163716077804565\n",
      "idx: 48, loss: 0.48762357234954834\n",
      "idx: 49, loss: 0.5449659824371338\n",
      "idx: 50, loss: 0.5931259393692017\n",
      "epoch: 1, idx: 50, loss: 0.5308982968330384\n",
      "epoch: 1, idx: 50, accuracy: 0.8032, loss: 0.0\n",
      "idx: 51, loss: 0.563427209854126\n",
      "idx: 52, loss: 0.607689142227173\n",
      "idx: 53, loss: 0.6018899083137512\n",
      "idx: 54, loss: 0.5903852581977844\n",
      "idx: 55, loss: 0.8196443915367128\n",
      "idx: 56, loss: 0.8176472783088684\n",
      "idx: 57, loss: 0.6920723319053649\n",
      "idx: 58, loss: 0.7000260353088378\n",
      "idx: 59, loss: 0.4758905172348023\n",
      "idx: 60, loss: 0.5129207968711853\n",
      "epoch: 1, idx: 60, loss: 0.6381592869758606\n",
      "epoch: 1, idx: 60, accuracy: 0.7706, loss: 0.0\n",
      "idx: 61, loss: 0.5391921997070312\n",
      "idx: 62, loss: 0.6136918067932129\n",
      "idx: 63, loss: 0.6044924855232238\n",
      "idx: 64, loss: 0.5124977231025697\n",
      "idx: 65, loss: 0.46481233835220337\n",
      "idx: 66, loss: 0.5637198686599731\n",
      "idx: 67, loss: 0.6282253861427306\n",
      "idx: 68, loss: 0.7173956632614135\n",
      "idx: 69, loss: 0.6239007711410522\n",
      "idx: 70, loss: 0.5485770106315613\n",
      "epoch: 1, idx: 70, loss: 0.5816505253314972\n",
      "epoch: 1, idx: 70, accuracy: 0.8208, loss: 0.0\n",
      "idx: 71, loss: 0.4773260354995727\n",
      "idx: 72, loss: 0.4912422299385071\n",
      "idx: 73, loss: 0.5103787183761597\n",
      "idx: 74, loss: 0.5193599462509155\n",
      "idx: 75, loss: 0.5261843800544739\n",
      "idx: 76, loss: 0.5932023525238038\n",
      "idx: 77, loss: 0.7036336660385131\n",
      "idx: 78, loss: 1.1093596816062925\n",
      "idx: 79, loss: 1.8952658772468565\n",
      "idx: 80, loss: 0.6414190530776978\n",
      "epoch: 1, idx: 80, loss: 0.7467371940612793\n",
      "epoch: 1, idx: 80, accuracy: 0.7656, loss: 0.0\n",
      "idx: 81, loss: 0.5031187534332274\n",
      "idx: 82, loss: 0.5457720756530762\n",
      "idx: 83, loss: 0.4943026900291443\n",
      "idx: 84, loss: 0.5478942394256592\n",
      "idx: 85, loss: 0.4698991179466247\n",
      "idx: 86, loss: 0.44703972339630127\n",
      "idx: 87, loss: 0.540663182735443\n",
      "idx: 88, loss: 0.5319184064865112\n",
      "idx: 89, loss: 0.8433257341384887\n",
      "idx: 90, loss: 0.623558759689331\n",
      "epoch: 1, idx: 90, loss: 0.5547492682933808\n",
      "epoch: 1, idx: 90, accuracy: 0.7719, loss: 0.0\n",
      "idx: 91, loss: 0.7371501326560973\n",
      "idx: 92, loss: 0.6216365694999696\n",
      "idx: 93, loss: 0.5106537938117981\n",
      "idx: 94, loss: 0.5009726285934447\n",
      "idx: 95, loss: 0.4890057444572449\n",
      "idx: 96, loss: 0.49625164270401\n",
      "idx: 97, loss: 0.5327976942062378\n",
      "idx: 98, loss: 0.43477123975753784\n",
      "idx: 99, loss: 0.5156642198562623\n",
      "idx: 100, loss: 0.4031928777694702\n",
      "epoch: 1, idx: 100, loss: 0.5242096543312073\n",
      "epoch: 1, idx: 100, accuracy: 0.8454, loss: 0.0\n",
      "idx: 101, loss: 0.4134890437126159\n",
      "idx: 102, loss: 0.4368178844451904\n",
      "idx: 103, loss: 0.4141534566879273\n",
      "idx: 104, loss: 0.4808688163757324\n",
      "idx: 105, loss: 0.48695492744445795\n",
      "idx: 106, loss: 0.4868830442428589\n",
      "idx: 107, loss: 0.5149743556976318\n",
      "idx: 108, loss: 0.4265597462654114\n",
      "idx: 109, loss: 0.4534200429916382\n",
      "idx: 110, loss: 0.45612734556198126\n",
      "epoch: 1, idx: 110, loss: 0.4570248663425446\n",
      "epoch: 1, idx: 110, accuracy: 0.8242, loss: 0.0\n",
      "idx: 111, loss: 0.5091603994369507\n",
      "idx: 112, loss: 0.47981876134872437\n",
      "idx: 113, loss: 0.5337775349617004\n",
      "idx: 114, loss: 0.5209957957267761\n",
      "idx: 115, loss: 0.5312395095825194\n",
      "idx: 116, loss: 0.48437196016311646\n",
      "idx: 117, loss: 0.5531848073005676\n",
      "idx: 118, loss: 0.48644405603408813\n",
      "idx: 119, loss: 0.4443017840385437\n",
      "idx: 120, loss: 0.5302509069442749\n",
      "epoch: 1, idx: 120, loss: 0.5073545515537262\n",
      "epoch: 1, idx: 120, accuracy: 0.8467, loss: 0.0\n",
      "idx: 121, loss: 0.49213695526123047\n",
      "idx: 122, loss: 0.43284076452255243\n",
      "idx: 123, loss: 0.48191881179809576\n",
      "idx: 124, loss: 0.4833682179450989\n",
      "idx: 125, loss: 0.4577445983886719\n",
      "idx: 126, loss: 0.47598457336425776\n",
      "idx: 127, loss: 0.6138609647750854\n",
      "idx: 128, loss: 0.4176254868507385\n",
      "idx: 129, loss: 0.4264117479324341\n",
      "idx: 130, loss: 0.4501891136169433\n",
      "epoch: 1, idx: 130, loss: 0.4732081234455109\n",
      "epoch: 1, idx: 130, accuracy: 0.849, loss: 0.0\n",
      "idx: 131, loss: 0.42579793930053705\n",
      "idx: 132, loss: 0.4110348224639892\n",
      "idx: 133, loss: 0.41479009389877325\n",
      "idx: 134, loss: 0.3997117877006531\n",
      "idx: 135, loss: 0.4624126553535462\n",
      "idx: 136, loss: 0.4512031674385071\n",
      "idx: 137, loss: 0.4702685475349426\n",
      "idx: 138, loss: 0.49769204854965216\n",
      "idx: 139, loss: 0.4978017807006836\n",
      "idx: 140, loss: 0.4963139295578003\n",
      "epoch: 1, idx: 140, loss: 0.4527026772499084\n",
      "epoch: 1, idx: 140, accuracy: 0.8557, loss: 0.0\n",
      "idx: 141, loss: 0.48785758018493647\n",
      "idx: 142, loss: 0.4613082408905029\n",
      "idx: 143, loss: 0.45771771669387823\n",
      "idx: 144, loss: 0.4656921029090882\n",
      "idx: 145, loss: 0.4759836196899414\n",
      "idx: 146, loss: 0.5195262432098389\n",
      "idx: 147, loss: 0.5158168673515321\n",
      "idx: 148, loss: 0.48828071355819697\n",
      "idx: 149, loss: 0.4500012397766113\n",
      "idx: 150, loss: 0.4742463827133179\n",
      "epoch: 1, idx: 150, loss: 0.47964307069778445\n",
      "epoch: 1, idx: 150, accuracy: 0.8421, loss: 0.0\n",
      "idx: 151, loss: 0.45271074771881104\n",
      "idx: 152, loss: 0.38301205635070795\n",
      "idx: 153, loss: 0.3881176710128785\n",
      "idx: 154, loss: 0.4814471602439881\n",
      "idx: 155, loss: 0.4660906791687011\n",
      "idx: 156, loss: 0.45383906364440924\n",
      "idx: 157, loss: 0.41193664073944086\n",
      "idx: 158, loss: 0.4022266268730164\n",
      "idx: 159, loss: 0.4101437330245972\n",
      "idx: 160, loss: 0.35887593030929565\n",
      "epoch: 1, idx: 160, loss: 0.4208400309085846\n",
      "epoch: 1, idx: 160, accuracy: 0.8663, loss: 0.0\n",
      "idx: 161, loss: 0.40175026655197144\n",
      "idx: 162, loss: 0.53570556640625\n",
      "idx: 163, loss: 0.4515370130538941\n",
      "idx: 164, loss: 0.4409395456314087\n",
      "idx: 165, loss: 0.48492044210433954\n",
      "idx: 166, loss: 0.49934113025665283\n",
      "idx: 167, loss: 0.44615346193313593\n",
      "idx: 168, loss: 0.45613628625869745\n",
      "idx: 169, loss: 0.4747573137283325\n",
      "idx: 170, loss: 0.38597375154495245\n",
      "epoch: 1, idx: 170, loss: 0.4577214777469635\n",
      "epoch: 1, idx: 170, accuracy: 0.8599, loss: 0.0\n",
      "idx: 171, loss: 0.3898918628692627\n",
      "idx: 172, loss: 0.4800472855567932\n",
      "idx: 173, loss: 0.47022539377212524\n",
      "idx: 174, loss: 0.4247092604637146\n",
      "idx: 175, loss: 0.3801089525222778\n",
      "idx: 176, loss: 0.42074364423751837\n",
      "idx: 177, loss: 0.4274325966835022\n",
      "idx: 178, loss: 0.4080078601837158\n",
      "idx: 179, loss: 0.42698931694030756\n",
      "idx: 180, loss: 0.44158375263214106\n",
      "epoch: 1, idx: 180, loss: 0.4269739925861359\n",
      "epoch: 1, idx: 180, accuracy: 0.8795, loss: 0.0\n",
      "idx: 181, loss: 0.4036861658096314\n",
      "idx: 182, loss: 0.4022792577743531\n",
      "idx: 183, loss: 0.4059852361679077\n",
      "idx: 184, loss: 0.3971439599990844\n",
      "idx: 185, loss: 0.43046486377716064\n",
      "idx: 186, loss: 0.4859284162521362\n",
      "idx: 187, loss: 0.41151934862136846\n",
      "idx: 188, loss: 0.41468375921249395\n",
      "idx: 189, loss: 0.3929148316383362\n",
      "idx: 190, loss: 0.4126396179199219\n",
      "epoch: 1, idx: 190, loss: 0.4157245457172394\n",
      "epoch: 1, idx: 190, accuracy: 0.8689, loss: 0.0\n",
      "idx: 191, loss: 0.3971461653709412\n",
      "idx: 192, loss: 0.5004905462265015\n",
      "idx: 193, loss: 0.42680549621582037\n",
      "idx: 194, loss: 0.5372923612594604\n",
      "idx: 195, loss: 0.4705171585083008\n",
      "idx: 196, loss: 0.4924623370170593\n",
      "idx: 197, loss: 0.48407477140426636\n",
      "idx: 198, loss: 0.3988229036331176\n",
      "idx: 199, loss: 0.4549104571342469\n",
      "idx: 200, loss: 0.39467531442642206\n",
      "epoch: 1, idx: 200, loss: 0.45571975111961366\n",
      "epoch: 1, idx: 200, accuracy: 0.8454, loss: 0.0\n",
      "idx: 201, loss: 0.44223833084106445\n",
      "idx: 202, loss: 0.35481870174407953\n",
      "idx: 203, loss: 0.4414564967155457\n",
      "idx: 204, loss: 0.5177697539329528\n",
      "idx: 205, loss: 0.4145981669425965\n",
      "idx: 206, loss: 0.3843990564346314\n",
      "idx: 207, loss: 0.47915118932724\n",
      "idx: 208, loss: 0.4574205875396729\n",
      "idx: 209, loss: 0.4252550601959228\n",
      "idx: 210, loss: 0.46002864837646484\n",
      "epoch: 1, idx: 210, loss: 0.43771359920501707\n",
      "epoch: 1, idx: 210, accuracy: 0.8435, loss: 0.0\n",
      "idx: 211, loss: 0.46661931276321417\n",
      "idx: 212, loss: 0.433879017829895\n",
      "idx: 213, loss: 0.5004741549491881\n",
      "idx: 214, loss: 0.4851763248443603\n",
      "idx: 215, loss: 0.5026620030403137\n",
      "idx: 216, loss: 0.4308406710624695\n",
      "idx: 217, loss: 0.4185253977775573\n",
      "idx: 218, loss: 0.427303671836853\n",
      "idx: 219, loss: 0.381082832813263\n",
      "idx: 220, loss: 0.41228687763214117\n",
      "epoch: 1, idx: 220, loss: 0.44588502645492556\n",
      "epoch: 1, idx: 220, accuracy: 0.8772, loss: 0.0\n",
      "idx: 221, loss: 0.4016578793525695\n",
      "idx: 222, loss: 0.40393245220184326\n",
      "idx: 223, loss: 0.38412618637084955\n",
      "idx: 224, loss: 0.3772993683815003\n",
      "idx: 225, loss: 0.409180998802185\n",
      "idx: 226, loss: 0.43852537870407104\n",
      "idx: 227, loss: 0.3905758261680603\n",
      "idx: 228, loss: 0.37512147426605225\n",
      "idx: 229, loss: 0.3731527924537659\n",
      "idx: 230, loss: 0.4296166896820068\n",
      "epoch: 1, idx: 230, loss: 0.3983189046382904\n",
      "epoch: 1, idx: 230, accuracy: 0.8432, loss: 0.0\n",
      "idx: 231, loss: 0.39137792587280273\n",
      "idx: 232, loss: 0.47566342353820795\n",
      "idx: 233, loss: 0.4446058869361877\n",
      "idx: 234, loss: 0.4134896993637085\n",
      "idx: 235, loss: 0.4421931902567546\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    tot_loss = 0\n",
    "    for train_idx, (train_data_batch, train_label_batch) in enumerate(zip(train_data, train_label)):\n",
    "        # train\n",
    "        preds = model.forward(train_data_batch)\n",
    "\n",
    "        loss = criterion.forward(preds, train_label_batch)\n",
    "        tot_loss += loss\n",
    "        propagated_error = criterion.error_derivative()\n",
    "\n",
    "        model.backprop(propagated_error)\n",
    "        model.optimize(LR)\n",
    "        print('idx: {}, loss: {}'.format(train_idx + 1, loss))\n",
    "        if (train_idx + 1) % PRINT == 0:\n",
    "            print('epoch: {}, idx: {}, loss: {}'.format(epoch + 1, train_idx + 1, tot_loss / PRINT))\n",
    "            tot_loss = 0\n",
    "\n",
    "        if (train_idx + 1) % PRINT == 0:\n",
    "            tot_acc = 0\n",
    "            tot_sample = 0\n",
    "            for train_acc_idx, (test_data_batch, test_label_batch) in enumerate(zip(test_data, test_label)):\n",
    "                # train accuracy\n",
    "                preds = model.forward(test_data_batch)\n",
    "                real_preds = to_real_domain(preds, QUANTIZATION_WEIGHT, PRIME)\n",
    "                pred_args = np.argmax(real_preds, axis=1)\n",
    "\n",
    "                tot_acc += np.count_nonzero(pred_args == test_label_batch)\n",
    "                tot_sample += test_data_batch.shape[0]\n",
    "\n",
    "            accuracy = tot_acc / tot_sample\n",
    "            if train_idx != 0:\n",
    "                tot_loss = tot_loss / PRINT\n",
    "            print('epoch: {}, idx: {}, accuracy: {}, loss: {}'.format(epoch + 1, train_idx + 1, accuracy, tot_loss))\n",
    "            tot_loss = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
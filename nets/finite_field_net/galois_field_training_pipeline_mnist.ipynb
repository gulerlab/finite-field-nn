{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:42.017217095Z",
     "start_time": "2023-06-23T11:38:40.967468871Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "from galois_datasets import load_all_data_mnist, load_all_data_cifar10, load_all_data_fashion_mnist\n",
    "from utils import create_batch_data, to_finite_field_domain, from_galois_to_real_domain\n",
    "import modules\n",
    "import galois_layers\n",
    "from galois_criterions import GaloisFieldMSELoss\n",
    "from sklearn.datasets import make_classification\n",
    "import galois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:42.019549983Z",
     "start_time": "2023-06-23T11:38:42.018499848Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 1\n",
    "PRINT = 1\n",
    "FLATTEN = False\n",
    "# 0, MNIST; 1, FashionMNIST; 2, CIFAR10; 3 RANDOM\n",
    "DATASET_MODE = 0\n",
    "\n",
    "QUANTIZATION_INPUT = 8\n",
    "QUANTIZATION_WEIGHT = 16\n",
    "QUANTIZATION_BATCH_SIZE = 8\n",
    "LR = 7\n",
    "PRIME = 684502462494449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:43.271300923Z",
     "start_time": "2023-06-23T11:38:42.754454712Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field = galois.GF(PRIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:43.517528143Z",
     "start_time": "2023-06-23T11:38:43.512054166Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data fetching\n",
    "load_path = '../../data'\n",
    "if DATASET_MODE == 0:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_mnist(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, field, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 1:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_fashion_mnist(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, field, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 2:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_cifar10(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, field, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 3:\n",
    "    train_data, train_label = make_classification(n_samples=10, n_features=100, n_classes=10, n_clusters_per_class=1, n_informative=10)\n",
    "    train_data = train_data.reshape((-1, 4, 5, 5))\n",
    "    test_data, test_label = train_data, train_label\n",
    "    train_label = np.zeros((10, 10))\n",
    "    for idx, label in enumerate(test_label):\n",
    "        train_label[idx][label] = 1\n",
    "    train_data, train_label, test_data = to_finite_field_domain(train_data, QUANTIZATION_INPUT, PRIME), to_finite_field_domain(train_label, QUANTIZATION_WEIGHT, PRIME), to_finite_field_domain(test_data, QUANTIZATION_INPUT, PRIME)\n",
    "    train_data, train_label, test_data = field(train_data), field(train_label), field(test_data)\n",
    "else:\n",
    "    train_data, train_label, test_data, test_label = None, None, None, None\n",
    "train_data, train_label, test_data, test_label = create_batch_data(train_data, train_label, test_data, test_label, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:44.174933932Z",
     "start_time": "2023-06-23T11:38:44.172059964Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_arr = [\n",
    "    galois_layers.GaloisFieldPiNetSecondOrderConvLayer(1, 6, (5, 5), QUANTIZATION_WEIGHT, PRIME, field, first_layer=True,\n",
    "                                                quantization_bit_input=QUANTIZATION_INPUT),\n",
    "    galois_layers.GaloisFieldPiNetSecondOrderConvLayer(6, 6, (5, 5), QUANTIZATION_WEIGHT, PRIME, field),\n",
    "    modules.Flatten(),\n",
    "    galois_layers.GaloisFieldPiNetSecondOrderLinearLayer(2400, 128, QUANTIZATION_WEIGHT, PRIME, field),\n",
    "    galois_layers.GaloisFieldLinearLayer(128, 10, QUANTIZATION_WEIGHT, PRIME, field)\n",
    "]\n",
    "\n",
    "model = modules.Network(model_arr)\n",
    "criterion = GaloisFieldMSELoss(PRIME, QUANTIZATION_WEIGHT, QUANTIZATION_BATCH_SIZE, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T11:41:20.925984317Z",
     "start_time": "2023-06-23T11:38:45.014257135Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, idx: 1, curr loss: 1.468828772892266\n",
      "epoch: 1, idx: 1, avg loss: 1.468828772892266\n",
      "epoch: 1, idx: 2, curr loss: 1.0373511156176394\n",
      "epoch: 1, idx: 2, avg loss: 1.0373511156176394\n",
      "epoch: 1, idx: 3, curr loss: 0.9575303546607755\n",
      "epoch: 1, idx: 3, avg loss: 0.9575303546607755\n",
      "epoch: 1, idx: 4, curr loss: 0.9297337685493402\n",
      "epoch: 1, idx: 4, avg loss: 0.9297337685493402\n",
      "epoch: 1, idx: 5, curr loss: 0.9147911656755241\n",
      "epoch: 1, idx: 5, avg loss: 0.9147911656755241\n",
      "epoch: 1, idx: 6, curr loss: 0.8402015753035812\n",
      "epoch: 1, idx: 6, avg loss: 0.8402015753035812\n",
      "epoch: 1, idx: 7, curr loss: 0.7775595990251531\n",
      "epoch: 1, idx: 7, avg loss: 0.7775595990251531\n",
      "epoch: 1, idx: 8, curr loss: 0.793746826368988\n",
      "epoch: 1, idx: 8, avg loss: 0.793746826368988\n",
      "epoch: 1, idx: 9, curr loss: 0.7356878174978192\n",
      "epoch: 1, idx: 9, avg loss: 0.7356878174978192\n",
      "epoch: 1, idx: 10, curr loss: 0.7275589056707757\n",
      "epoch: 1, idx: 10, avg loss: 0.7275589056707757\n",
      "epoch: 1, idx: 11, curr loss: 0.7172351948183859\n",
      "epoch: 1, idx: 11, avg loss: 0.7172351948183859\n",
      "epoch: 1, idx: 12, curr loss: 0.6713208653645779\n",
      "epoch: 1, idx: 12, avg loss: 0.6713208653645779\n",
      "epoch: 1, idx: 13, curr loss: 0.6737039490826646\n",
      "epoch: 1, idx: 13, avg loss: 0.6737039490826646\n",
      "epoch: 1, idx: 14, curr loss: 0.6677835410628177\n",
      "epoch: 1, idx: 14, avg loss: 0.6677835410628177\n",
      "epoch: 1, idx: 15, curr loss: 0.6640348809223723\n",
      "epoch: 1, idx: 15, avg loss: 0.6640348809223723\n",
      "epoch: 1, idx: 16, curr loss: 0.6160113625337544\n",
      "epoch: 1, idx: 16, avg loss: 0.6160113625337544\n",
      "epoch: 1, idx: 17, curr loss: 0.6110285953482162\n",
      "epoch: 1, idx: 17, avg loss: 0.6110285953482162\n",
      "epoch: 1, idx: 18, curr loss: 0.5843009159343637\n",
      "epoch: 1, idx: 18, avg loss: 0.5843009159343637\n",
      "epoch: 1, idx: 19, curr loss: 0.6233761048497399\n",
      "epoch: 1, idx: 19, avg loss: 0.6233761048497399\n",
      "epoch: 1, idx: 20, curr loss: 0.5751654318773944\n",
      "epoch: 1, idx: 20, avg loss: 0.5751654318773944\n",
      "epoch: 1, idx: 21, curr loss: 0.5657127381118698\n",
      "epoch: 1, idx: 21, avg loss: 0.5657127381118698\n",
      "epoch: 1, idx: 22, curr loss: 0.5500068791907324\n",
      "epoch: 1, idx: 22, avg loss: 0.5500068791907324\n",
      "epoch: 1, idx: 23, curr loss: 0.5681778427533573\n",
      "epoch: 1, idx: 23, avg loss: 0.5681778427533573\n",
      "epoch: 1, idx: 24, curr loss: 0.5487050530709894\n",
      "epoch: 1, idx: 24, avg loss: 0.5487050530709894\n",
      "epoch: 1, idx: 25, curr loss: 0.5340765382925383\n",
      "epoch: 1, idx: 25, avg loss: 0.5340765382925383\n",
      "epoch: 1, idx: 26, curr loss: 0.49915702619273356\n",
      "epoch: 1, idx: 26, avg loss: 0.49915702619273356\n",
      "epoch: 1, idx: 27, curr loss: 0.564492269290895\n",
      "epoch: 1, idx: 27, avg loss: 0.564492269290895\n",
      "epoch: 1, idx: 28, curr loss: 0.5496173103465479\n",
      "epoch: 1, idx: 28, avg loss: 0.5496173103465479\n",
      "epoch: 1, idx: 29, curr loss: 0.5941309299814748\n",
      "epoch: 1, idx: 29, avg loss: 0.5941309299814748\n",
      "epoch: 1, idx: 30, curr loss: 0.5308251955248124\n",
      "epoch: 1, idx: 30, avg loss: 0.5308251955248124\n",
      "epoch: 1, idx: 31, curr loss: 0.5526406068338474\n",
      "epoch: 1, idx: 31, avg loss: 0.5526406068338474\n",
      "epoch: 1, idx: 32, curr loss: 0.5241856909715352\n",
      "epoch: 1, idx: 32, avg loss: 0.5241856909715352\n",
      "epoch: 1, idx: 33, curr loss: 0.5348039664850148\n",
      "epoch: 1, idx: 33, avg loss: 0.5348039664850148\n",
      "epoch: 1, idx: 34, curr loss: 0.5335851137551798\n",
      "epoch: 1, idx: 34, avg loss: 0.5335851137551798\n",
      "epoch: 1, idx: 35, curr loss: 0.5529732729100942\n",
      "epoch: 1, idx: 35, avg loss: 0.5529732729100942\n",
      "epoch: 1, idx: 36, curr loss: 0.46130254246691044\n",
      "epoch: 1, idx: 36, avg loss: 0.46130254246691044\n",
      "epoch: 1, idx: 37, curr loss: 0.4825431491372001\n",
      "epoch: 1, idx: 37, avg loss: 0.4825431491372001\n",
      "epoch: 1, idx: 38, curr loss: 0.46807231280399714\n",
      "epoch: 1, idx: 38, avg loss: 0.46807231280399714\n",
      "epoch: 1, idx: 39, curr loss: 0.4521724561091105\n",
      "epoch: 1, idx: 39, avg loss: 0.4521724561091105\n",
      "epoch: 1, idx: 40, curr loss: 0.4799523510428117\n",
      "epoch: 1, idx: 40, avg loss: 0.4799523510428117\n",
      "epoch: 1, idx: 41, curr loss: 0.4422191276580633\n",
      "epoch: 1, idx: 41, avg loss: 0.4422191276580633\n",
      "epoch: 1, idx: 42, curr loss: 0.4517880487319417\n",
      "epoch: 1, idx: 42, avg loss: 0.4517880487319417\n",
      "epoch: 1, idx: 43, curr loss: 0.42371354312490433\n",
      "epoch: 1, idx: 43, avg loss: 0.42371354312490433\n",
      "epoch: 1, idx: 44, curr loss: 0.4478261741087408\n",
      "epoch: 1, idx: 44, avg loss: 0.4478261741087408\n",
      "epoch: 1, idx: 45, curr loss: 0.42017145210957096\n",
      "epoch: 1, idx: 45, avg loss: 0.42017145210957096\n",
      "epoch: 1, idx: 46, curr loss: 0.5156436907800526\n",
      "epoch: 1, idx: 46, avg loss: 0.5156436907800526\n",
      "epoch: 1, idx: 47, curr loss: 0.442623776639266\n",
      "epoch: 1, idx: 47, avg loss: 0.442623776639266\n",
      "epoch: 1, idx: 48, curr loss: 0.4282150785338672\n",
      "epoch: 1, idx: 48, avg loss: 0.4282150785338672\n",
      "epoch: 1, idx: 49, curr loss: 0.46537677622109186\n",
      "epoch: 1, idx: 49, avg loss: 0.46537677622109186\n",
      "epoch: 1, idx: 50, curr loss: 0.47471365413548483\n",
      "epoch: 1, idx: 50, avg loss: 0.47471365413548483\n",
      "epoch: 1, idx: 51, curr loss: 0.4666001349833095\n",
      "epoch: 1, idx: 51, avg loss: 0.4666001349833095\n",
      "epoch: 1, idx: 52, curr loss: 0.4609448683659138\n",
      "epoch: 1, idx: 52, avg loss: 0.4609448683659138\n",
      "epoch: 1, idx: 53, curr loss: 0.41336982051598176\n",
      "epoch: 1, idx: 53, avg loss: 0.41336982051598176\n",
      "epoch: 1, idx: 54, curr loss: 0.44253189656319586\n",
      "epoch: 1, idx: 54, avg loss: 0.44253189656319586\n",
      "epoch: 1, idx: 55, curr loss: 0.47587652594666\n",
      "epoch: 1, idx: 55, avg loss: 0.47587652594666\n",
      "epoch: 1, idx: 56, curr loss: 0.4644789231379037\n",
      "epoch: 1, idx: 56, avg loss: 0.4644789231379037\n",
      "epoch: 1, idx: 57, curr loss: 0.4724707470622888\n",
      "epoch: 1, idx: 57, avg loss: 0.4724707470622888\n",
      "epoch: 1, idx: 58, curr loss: 0.527461968253192\n",
      "epoch: 1, idx: 58, avg loss: 0.527461968253192\n",
      "epoch: 1, idx: 59, curr loss: 0.3757927204869702\n",
      "epoch: 1, idx: 59, avg loss: 0.3757927204869702\n",
      "epoch: 1, idx: 60, curr loss: 0.4183355005297926\n",
      "epoch: 1, idx: 60, avg loss: 0.4183355005297926\n",
      "epoch: 1, idx: 61, curr loss: 0.40189876406111574\n",
      "epoch: 1, idx: 61, avg loss: 0.40189876406111574\n",
      "epoch: 1, idx: 62, curr loss: 0.47029824053515773\n",
      "epoch: 1, idx: 62, avg loss: 0.47029824053515773\n",
      "epoch: 1, idx: 63, curr loss: 0.45548573252290225\n",
      "epoch: 1, idx: 63, avg loss: 0.45548573252290225\n",
      "epoch: 1, idx: 64, curr loss: 0.3925477276206948\n",
      "epoch: 1, idx: 64, avg loss: 0.3925477276206948\n",
      "epoch: 1, idx: 65, curr loss: 0.3497619009549453\n",
      "epoch: 1, idx: 65, avg loss: 0.3497619009549453\n",
      "epoch: 1, idx: 66, curr loss: 0.4239398474119298\n",
      "epoch: 1, idx: 66, avg loss: 0.4239398474119298\n",
      "epoch: 1, idx: 67, curr loss: 0.4373943390546628\n",
      "epoch: 1, idx: 67, avg loss: 0.4373943390546628\n",
      "epoch: 1, idx: 68, curr loss: 0.39545087182341376\n",
      "epoch: 1, idx: 68, avg loss: 0.39545087182341376\n",
      "epoch: 1, idx: 69, curr loss: 0.4507629029703822\n",
      "epoch: 1, idx: 69, avg loss: 0.4507629029703822\n",
      "epoch: 1, idx: 70, curr loss: 0.44102285433837096\n",
      "epoch: 1, idx: 70, avg loss: 0.44102285433837096\n",
      "epoch: 1, idx: 71, curr loss: 0.3544229724939214\n",
      "epoch: 1, idx: 71, avg loss: 0.3544229724939214\n",
      "epoch: 1, idx: 72, curr loss: 0.3658793170752687\n",
      "epoch: 1, idx: 72, avg loss: 0.3658793170752687\n",
      "epoch: 1, idx: 73, curr loss: 0.3715641989947472\n",
      "epoch: 1, idx: 73, avg loss: 0.3715641989947472\n",
      "epoch: 1, idx: 74, curr loss: 0.3316919224507728\n",
      "epoch: 1, idx: 74, avg loss: 0.3316919224507728\n",
      "epoch: 1, idx: 75, curr loss: 0.38659885076140205\n",
      "epoch: 1, idx: 75, avg loss: 0.38659885076140205\n",
      "epoch: 1, idx: 76, curr loss: 0.3644516612648659\n",
      "epoch: 1, idx: 76, avg loss: 0.3644516612648659\n",
      "epoch: 1, idx: 77, curr loss: 0.35078248859372246\n",
      "epoch: 1, idx: 77, avg loss: 0.35078248859372246\n",
      "epoch: 1, idx: 78, curr loss: 0.38054797470158513\n",
      "epoch: 1, idx: 78, avg loss: 0.38054797470158513\n",
      "epoch: 1, idx: 79, curr loss: 0.4358127910563781\n",
      "epoch: 1, idx: 79, avg loss: 0.4358127910563781\n",
      "epoch: 1, idx: 80, curr loss: 0.3567902855984358\n",
      "epoch: 1, idx: 80, avg loss: 0.3567902855984358\n",
      "epoch: 1, idx: 81, curr loss: 0.3415398451270449\n",
      "epoch: 1, idx: 81, avg loss: 0.3415398451270449\n",
      "epoch: 1, idx: 82, curr loss: 0.3890437702530108\n",
      "epoch: 1, idx: 82, avg loss: 0.3890437702530108\n",
      "epoch: 1, idx: 83, curr loss: 0.33316976748938026\n",
      "epoch: 1, idx: 83, avg loss: 0.33316976748938026\n",
      "epoch: 1, idx: 84, curr loss: 0.3780286763212643\n",
      "epoch: 1, idx: 84, avg loss: 0.3780286763212643\n",
      "epoch: 1, idx: 85, curr loss: 0.35252158050298016\n",
      "epoch: 1, idx: 85, avg loss: 0.35252158050298016\n",
      "epoch: 1, idx: 86, curr loss: 0.3188970804221753\n",
      "epoch: 1, idx: 86, avg loss: 0.3188970804221753\n",
      "epoch: 1, idx: 87, curr loss: 0.42503992903129983\n",
      "epoch: 1, idx: 87, avg loss: 0.42503992903129983\n",
      "epoch: 1, idx: 88, curr loss: 0.3820237248264675\n",
      "epoch: 1, idx: 88, avg loss: 0.3820237248264675\n",
      "epoch: 1, idx: 89, curr loss: 0.4282638813665472\n",
      "epoch: 1, idx: 89, avg loss: 0.4282638813665472\n",
      "epoch: 1, idx: 90, curr loss: 0.3120228620136914\n",
      "epoch: 1, idx: 90, avg loss: 0.3120228620136914\n",
      "epoch: 1, idx: 91, curr loss: 0.36489866383180924\n",
      "epoch: 1, idx: 91, avg loss: 0.36489866383180924\n",
      "epoch: 1, idx: 92, curr loss: 0.3400516620431518\n",
      "epoch: 1, idx: 92, avg loss: 0.3400516620431518\n",
      "epoch: 1, idx: 93, curr loss: 0.38327988217588427\n",
      "epoch: 1, idx: 93, avg loss: 0.38327988217588427\n",
      "epoch: 1, idx: 94, curr loss: 0.37560068566835986\n",
      "epoch: 1, idx: 94, avg loss: 0.37560068566835986\n",
      "epoch: 1, idx: 95, curr loss: 0.3502698590446016\n",
      "epoch: 1, idx: 95, avg loss: 0.3502698590446016\n",
      "epoch: 1, idx: 96, curr loss: 0.34308238775520294\n",
      "epoch: 1, idx: 96, avg loss: 0.34308238775520294\n",
      "epoch: 1, idx: 97, curr loss: 0.3813466919846178\n",
      "epoch: 1, idx: 97, avg loss: 0.3813466919846178\n",
      "epoch: 1, idx: 98, curr loss: 0.32591031166703033\n",
      "epoch: 1, idx: 98, avg loss: 0.32591031166703033\n",
      "epoch: 1, idx: 99, curr loss: 0.3459493039254085\n",
      "epoch: 1, idx: 99, avg loss: 0.3459493039254085\n",
      "epoch: 1, idx: 100, curr loss: 0.30101457600630965\n",
      "epoch: 1, idx: 100, avg loss: 0.30101457600630965\n",
      "epoch: 1, idx: 101, curr loss: 0.31570222350910626\n",
      "epoch: 1, idx: 101, avg loss: 0.31570222350910626\n",
      "epoch: 1, idx: 102, curr loss: 0.331672863685526\n",
      "epoch: 1, idx: 102, avg loss: 0.331672863685526\n",
      "epoch: 1, idx: 103, curr loss: 0.30493430213846295\n",
      "epoch: 1, idx: 103, avg loss: 0.30493430213846295\n",
      "epoch: 1, idx: 104, curr loss: 0.3747504141783793\n",
      "epoch: 1, idx: 104, avg loss: 0.3747504141783793\n",
      "epoch: 1, idx: 105, curr loss: 0.3684528935418711\n",
      "epoch: 1, idx: 105, avg loss: 0.3684528935418711\n",
      "epoch: 1, idx: 106, curr loss: 0.3423928435522612\n",
      "epoch: 1, idx: 106, avg loss: 0.3423928435522612\n",
      "epoch: 1, idx: 107, curr loss: 0.3708949884830873\n",
      "epoch: 1, idx: 107, avg loss: 0.3708949884830873\n",
      "epoch: 1, idx: 108, curr loss: 0.3290429272528855\n",
      "epoch: 1, idx: 108, avg loss: 0.3290429272528855\n",
      "epoch: 1, idx: 109, curr loss: 0.34789582827943377\n",
      "epoch: 1, idx: 109, avg loss: 0.34789582827943377\n",
      "epoch: 1, idx: 110, curr loss: 0.2847622088693243\n",
      "epoch: 1, idx: 110, avg loss: 0.2847622088693243\n",
      "epoch: 1, idx: 111, curr loss: 0.3321448017095463\n",
      "epoch: 1, idx: 111, avg loss: 0.3321448017095463\n",
      "epoch: 1, idx: 112, curr loss: 0.32425536248229037\n",
      "epoch: 1, idx: 112, avg loss: 0.32425536248229037\n",
      "epoch: 1, idx: 113, curr loss: 0.3234853259837109\n",
      "epoch: 1, idx: 113, avg loss: 0.3234853259837109\n",
      "epoch: 1, idx: 114, curr loss: 0.36691890243127995\n",
      "epoch: 1, idx: 114, avg loss: 0.36691890243127995\n",
      "epoch: 1, idx: 115, curr loss: 0.31987208357531927\n",
      "epoch: 1, idx: 115, avg loss: 0.31987208357531927\n",
      "epoch: 1, idx: 116, curr loss: 0.3023443091760783\n",
      "epoch: 1, idx: 116, avg loss: 0.3023443091760783\n",
      "epoch: 1, idx: 117, curr loss: 0.4012893747176349\n",
      "epoch: 1, idx: 117, avg loss: 0.4012893747176349\n",
      "epoch: 1, idx: 118, curr loss: 0.3891806961837574\n",
      "epoch: 1, idx: 118, avg loss: 0.3891806961837574\n",
      "epoch: 1, idx: 119, curr loss: 0.32063056694187253\n",
      "epoch: 1, idx: 119, avg loss: 0.32063056694187253\n",
      "epoch: 1, idx: 120, curr loss: 0.3655613857126809\n",
      "epoch: 1, idx: 120, avg loss: 0.3655613857126809\n",
      "epoch: 1, idx: 121, curr loss: 0.3373212200622219\n",
      "epoch: 1, idx: 121, avg loss: 0.3373212200622219\n",
      "epoch: 1, idx: 122, curr loss: 0.3068593924235757\n",
      "epoch: 1, idx: 122, avg loss: 0.3068593924235757\n",
      "epoch: 1, idx: 123, curr loss: 0.36824939561029163\n",
      "epoch: 1, idx: 123, avg loss: 0.36824939561029163\n",
      "epoch: 1, idx: 124, curr loss: 0.37158797539632354\n",
      "epoch: 1, idx: 124, avg loss: 0.37158797539632354\n",
      "epoch: 1, idx: 125, curr loss: 0.3259451276744585\n",
      "epoch: 1, idx: 125, avg loss: 0.3259451276744585\n",
      "epoch: 1, idx: 126, curr loss: 0.3340816690051725\n",
      "epoch: 1, idx: 126, avg loss: 0.3340816690051725\n",
      "epoch: 1, idx: 127, curr loss: 0.4098998733707049\n",
      "epoch: 1, idx: 127, avg loss: 0.4098998733707049\n",
      "epoch: 1, idx: 128, curr loss: 0.29937744529797783\n",
      "epoch: 1, idx: 128, avg loss: 0.29937744529797783\n",
      "epoch: 1, idx: 129, curr loss: 0.2840623908732596\n",
      "epoch: 1, idx: 129, avg loss: 0.2840623908732596\n",
      "epoch: 1, idx: 130, curr loss: 0.32710997406775283\n",
      "epoch: 1, idx: 130, avg loss: 0.32710997406775283\n",
      "epoch: 1, idx: 131, curr loss: 0.3199728350728037\n",
      "epoch: 1, idx: 131, avg loss: 0.3199728350728037\n",
      "epoch: 1, idx: 132, curr loss: 0.277464197270092\n",
      "epoch: 1, idx: 132, avg loss: 0.277464197270092\n",
      "epoch: 1, idx: 133, curr loss: 0.25713443648965045\n",
      "epoch: 1, idx: 133, avg loss: 0.25713443648965045\n",
      "epoch: 1, idx: 134, curr loss: 0.27392483194398665\n",
      "epoch: 1, idx: 134, avg loss: 0.27392483194398665\n",
      "epoch: 1, idx: 135, curr loss: 0.3123588013913832\n",
      "epoch: 1, idx: 135, avg loss: 0.3123588013913832\n",
      "epoch: 1, idx: 136, curr loss: 0.3292025575256048\n",
      "epoch: 1, idx: 136, avg loss: 0.3292025575256048\n",
      "epoch: 1, idx: 137, curr loss: 0.31565606534331897\n",
      "epoch: 1, idx: 137, avg loss: 0.31565606534331897\n",
      "epoch: 1, idx: 138, curr loss: 0.30723524602217367\n",
      "epoch: 1, idx: 138, avg loss: 0.30723524602217367\n",
      "epoch: 1, idx: 139, curr loss: 0.2932736422126255\n",
      "epoch: 1, idx: 139, avg loss: 0.2932736422126255\n",
      "epoch: 1, idx: 140, curr loss: 0.2880536474049223\n",
      "epoch: 1, idx: 140, avg loss: 0.2880536474049223\n",
      "epoch: 1, idx: 141, curr loss: 0.3358563829015111\n",
      "epoch: 1, idx: 141, avg loss: 0.3358563829015111\n",
      "epoch: 1, idx: 142, curr loss: 0.3010541134835876\n",
      "epoch: 1, idx: 142, avg loss: 0.3010541134835876\n",
      "epoch: 1, idx: 143, curr loss: 0.30217549748613237\n",
      "epoch: 1, idx: 143, avg loss: 0.30217549748613237\n",
      "epoch: 1, idx: 144, curr loss: 0.29461956434170133\n",
      "epoch: 1, idx: 144, avg loss: 0.29461956434170133\n",
      "epoch: 1, idx: 145, curr loss: 0.31311601312245335\n",
      "epoch: 1, idx: 145, avg loss: 0.31311601312245335\n",
      "epoch: 1, idx: 146, curr loss: 0.2978504722468642\n",
      "epoch: 1, idx: 146, avg loss: 0.2978504722468642\n",
      "epoch: 1, idx: 147, curr loss: 0.34638990398798347\n",
      "epoch: 1, idx: 147, avg loss: 0.34638990398798347\n",
      "epoch: 1, idx: 148, curr loss: 0.3143273467248946\n",
      "epoch: 1, idx: 148, avg loss: 0.3143273467248946\n",
      "epoch: 1, idx: 149, curr loss: 0.28186518731035903\n",
      "epoch: 1, idx: 149, avg loss: 0.28186518731035903\n",
      "epoch: 1, idx: 150, curr loss: 0.31450885499816655\n",
      "epoch: 1, idx: 150, avg loss: 0.31450885499816655\n",
      "epoch: 1, idx: 151, curr loss: 0.30450623275373795\n",
      "epoch: 1, idx: 151, avg loss: 0.30450623275373795\n",
      "epoch: 1, idx: 152, curr loss: 0.269715983480637\n",
      "epoch: 1, idx: 152, avg loss: 0.269715983480637\n",
      "epoch: 1, idx: 153, curr loss: 0.2414665913429417\n",
      "epoch: 1, idx: 153, avg loss: 0.2414665913429417\n",
      "epoch: 1, idx: 154, curr loss: 0.32856208171233453\n",
      "epoch: 1, idx: 154, avg loss: 0.32856208171233453\n",
      "epoch: 1, idx: 155, curr loss: 0.2944432012764082\n",
      "epoch: 1, idx: 155, avg loss: 0.2944432012764082\n",
      "epoch: 1, idx: 156, curr loss: 0.348591582393965\n",
      "epoch: 1, idx: 156, avg loss: 0.348591582393965\n",
      "epoch: 1, idx: 157, curr loss: 0.2766151361065568\n",
      "epoch: 1, idx: 157, avg loss: 0.2766151361065568\n",
      "epoch: 1, idx: 158, curr loss: 0.2690474112905577\n",
      "epoch: 1, idx: 158, avg loss: 0.2690474112905577\n",
      "epoch: 1, idx: 159, curr loss: 0.29250703849447746\n",
      "epoch: 1, idx: 159, avg loss: 0.29250703849447746\n",
      "epoch: 1, idx: 160, curr loss: 0.2615821132476412\n",
      "epoch: 1, idx: 160, avg loss: 0.2615821132476412\n",
      "epoch: 1, idx: 161, curr loss: 0.28153365409616526\n",
      "epoch: 1, idx: 161, avg loss: 0.28153365409616526\n",
      "epoch: 1, idx: 162, curr loss: 0.3625050485570682\n",
      "epoch: 1, idx: 162, avg loss: 0.3625050485570682\n",
      "epoch: 1, idx: 163, curr loss: 0.31393368231510976\n",
      "epoch: 1, idx: 163, avg loss: 0.31393368231510976\n",
      "epoch: 1, idx: 164, curr loss: 0.279830721387043\n",
      "epoch: 1, idx: 164, avg loss: 0.279830721387043\n",
      "epoch: 1, idx: 165, curr loss: 0.29095733316262334\n",
      "epoch: 1, idx: 165, avg loss: 0.29095733316262334\n",
      "epoch: 1, idx: 166, curr loss: 0.3348677040448819\n",
      "epoch: 1, idx: 166, avg loss: 0.3348677040448819\n",
      "epoch: 1, idx: 167, curr loss: 0.2938431503371248\n",
      "epoch: 1, idx: 167, avg loss: 0.2938431503371248\n",
      "epoch: 1, idx: 168, curr loss: 0.3011952955612287\n",
      "epoch: 1, idx: 168, avg loss: 0.3011952955612287\n",
      "epoch: 1, idx: 169, curr loss: 0.30597267944995116\n",
      "epoch: 1, idx: 169, avg loss: 0.30597267944995116\n",
      "epoch: 1, idx: 170, curr loss: 0.2366714154577494\n",
      "epoch: 1, idx: 170, avg loss: 0.2366714154577494\n",
      "epoch: 1, idx: 171, curr loss: 0.23987989328361436\n",
      "epoch: 1, idx: 171, avg loss: 0.23987989328361436\n",
      "epoch: 1, idx: 172, curr loss: 0.28502539817964134\n",
      "epoch: 1, idx: 172, avg loss: 0.28502539817964134\n",
      "epoch: 1, idx: 173, curr loss: 0.30624512277972826\n",
      "epoch: 1, idx: 173, avg loss: 0.30624512277972826\n",
      "epoch: 1, idx: 174, curr loss: 0.28487374240921776\n",
      "epoch: 1, idx: 174, avg loss: 0.28487374240921776\n",
      "epoch: 1, idx: 175, curr loss: 0.24507133470160627\n",
      "epoch: 1, idx: 175, avg loss: 0.24507133470160627\n",
      "epoch: 1, idx: 176, curr loss: 0.3040499999206077\n",
      "epoch: 1, idx: 176, avg loss: 0.3040499999206077\n",
      "epoch: 1, idx: 177, curr loss: 0.2737399799134436\n",
      "epoch: 1, idx: 177, avg loss: 0.2737399799134436\n",
      "epoch: 1, idx: 178, curr loss: 0.2968767435868358\n",
      "epoch: 1, idx: 178, avg loss: 0.2968767435868358\n",
      "epoch: 1, idx: 179, curr loss: 0.3019562662302632\n",
      "epoch: 1, idx: 179, avg loss: 0.3019562662302632\n",
      "epoch: 1, idx: 180, curr loss: 0.3323894536242733\n",
      "epoch: 1, idx: 180, avg loss: 0.3323894536242733\n",
      "epoch: 1, idx: 181, curr loss: 0.3122275289670142\n",
      "epoch: 1, idx: 181, avg loss: 0.3122275289670142\n",
      "epoch: 1, idx: 182, curr loss: 0.2960377475974382\n",
      "epoch: 1, idx: 182, avg loss: 0.2960377475974382\n",
      "epoch: 1, idx: 183, curr loss: 0.25498444094046135\n",
      "epoch: 1, idx: 183, avg loss: 0.25498444094046135\n",
      "epoch: 1, idx: 184, curr loss: 0.24364355620400602\n",
      "epoch: 1, idx: 184, avg loss: 0.24364355620400602\n",
      "epoch: 1, idx: 185, curr loss: 0.29042915335321595\n",
      "epoch: 1, idx: 185, avg loss: 0.29042915335321595\n",
      "epoch: 1, idx: 186, curr loss: 0.32540021908152994\n",
      "epoch: 1, idx: 186, avg loss: 0.32540021908152994\n",
      "epoch: 1, idx: 187, curr loss: 0.24090253129179476\n",
      "epoch: 1, idx: 187, avg loss: 0.24090253129179476\n",
      "epoch: 1, idx: 188, curr loss: 0.26584850956533046\n",
      "epoch: 1, idx: 188, avg loss: 0.26584850956533046\n",
      "epoch: 1, idx: 189, curr loss: 0.2613255639471391\n",
      "epoch: 1, idx: 189, avg loss: 0.2613255639471391\n",
      "epoch: 1, idx: 190, curr loss: 0.2489770646261604\n",
      "epoch: 1, idx: 190, avg loss: 0.2489770646261604\n",
      "epoch: 1, idx: 191, curr loss: 0.24406329148496297\n",
      "epoch: 1, idx: 191, avg loss: 0.24406329148496297\n",
      "epoch: 1, idx: 192, curr loss: 0.3403953174620256\n",
      "epoch: 1, idx: 192, avg loss: 0.3403953174620256\n",
      "epoch: 1, idx: 193, curr loss: 0.26189980085655407\n",
      "epoch: 1, idx: 193, avg loss: 0.26189980085655407\n",
      "epoch: 1, idx: 194, curr loss: 0.36848915469363414\n",
      "epoch: 1, idx: 194, avg loss: 0.36848915469363414\n",
      "epoch: 1, idx: 195, curr loss: 0.2896616819016345\n",
      "epoch: 1, idx: 195, avg loss: 0.2896616819016345\n",
      "epoch: 1, idx: 196, curr loss: 0.26176970189044374\n",
      "epoch: 1, idx: 196, avg loss: 0.26176970189044374\n",
      "epoch: 1, idx: 197, curr loss: 0.3072502475333749\n",
      "epoch: 1, idx: 197, avg loss: 0.3072502475333749\n",
      "epoch: 1, idx: 198, curr loss: 0.2734235105162952\n",
      "epoch: 1, idx: 198, avg loss: 0.2734235105162952\n",
      "epoch: 1, idx: 199, curr loss: 0.28536192840783764\n",
      "epoch: 1, idx: 199, avg loss: 0.28536192840783764\n",
      "epoch: 1, idx: 200, curr loss: 0.24313784879177547\n",
      "epoch: 1, idx: 200, avg loss: 0.24313784879177547\n",
      "epoch: 1, idx: 201, curr loss: 0.24539050183284417\n",
      "epoch: 1, idx: 201, avg loss: 0.24539050183284417\n",
      "epoch: 1, idx: 202, curr loss: 0.22312215147485406\n",
      "epoch: 1, idx: 202, avg loss: 0.22312215147485406\n",
      "epoch: 1, idx: 203, curr loss: 0.24477848102742428\n",
      "epoch: 1, idx: 203, avg loss: 0.24477848102742428\n",
      "epoch: 1, idx: 204, curr loss: 0.3157175289115912\n",
      "epoch: 1, idx: 204, avg loss: 0.3157175289115912\n",
      "epoch: 1, idx: 205, curr loss: 0.2462050045996875\n",
      "epoch: 1, idx: 205, avg loss: 0.2462050045996875\n",
      "epoch: 1, idx: 206, curr loss: 0.23219228368270708\n",
      "epoch: 1, idx: 206, avg loss: 0.23219228368270708\n",
      "epoch: 1, idx: 207, curr loss: 0.3196159656736199\n",
      "epoch: 1, idx: 207, avg loss: 0.3196159656736199\n",
      "epoch: 1, idx: 208, curr loss: 0.2650566461043127\n",
      "epoch: 1, idx: 208, avg loss: 0.2650566461043127\n",
      "epoch: 1, idx: 209, curr loss: 0.21869714223976192\n",
      "epoch: 1, idx: 209, avg loss: 0.21869714223976192\n",
      "epoch: 1, idx: 210, curr loss: 0.27068269065694045\n",
      "epoch: 1, idx: 210, avg loss: 0.27068269065694045\n",
      "epoch: 1, idx: 211, curr loss: 0.27140522299487196\n",
      "epoch: 1, idx: 211, avg loss: 0.27140522299487196\n",
      "epoch: 1, idx: 212, curr loss: 0.258451244585558\n",
      "epoch: 1, idx: 212, avg loss: 0.258451244585558\n",
      "epoch: 1, idx: 213, curr loss: 0.22976372349421578\n",
      "epoch: 1, idx: 213, avg loss: 0.22976372349421578\n",
      "epoch: 1, idx: 214, curr loss: 0.22320345050684406\n",
      "epoch: 1, idx: 214, avg loss: 0.22320345050684406\n",
      "epoch: 1, idx: 215, curr loss: 0.29478840777483134\n",
      "epoch: 1, idx: 215, avg loss: 0.29478840777483134\n",
      "epoch: 1, idx: 216, curr loss: 0.2317922405509307\n",
      "epoch: 1, idx: 216, avg loss: 0.2317922405509307\n",
      "epoch: 1, idx: 217, curr loss: 0.2521365199518187\n",
      "epoch: 1, idx: 217, avg loss: 0.2521365199518187\n",
      "epoch: 1, idx: 218, curr loss: 0.24485821449889048\n",
      "epoch: 1, idx: 218, avg loss: 0.24485821449889048\n",
      "epoch: 1, idx: 219, curr loss: 0.20459539682997274\n",
      "epoch: 1, idx: 219, avg loss: 0.20459539682997274\n",
      "epoch: 1, idx: 220, curr loss: 0.24588031013263392\n",
      "epoch: 1, idx: 220, avg loss: 0.24588031013263392\n",
      "epoch: 1, idx: 221, curr loss: 0.25317908637589426\n",
      "epoch: 1, idx: 221, avg loss: 0.25317908637589426\n",
      "epoch: 1, idx: 222, curr loss: 0.24728136404792164\n",
      "epoch: 1, idx: 222, avg loss: 0.24728136404792164\n",
      "epoch: 1, idx: 223, curr loss: 0.2273723811013042\n",
      "epoch: 1, idx: 223, avg loss: 0.2273723811013042\n",
      "epoch: 1, idx: 224, curr loss: 0.24163199224494744\n",
      "epoch: 1, idx: 224, avg loss: 0.24163199224494744\n",
      "epoch: 1, idx: 225, curr loss: 0.247889120048967\n",
      "epoch: 1, idx: 225, avg loss: 0.247889120048967\n",
      "epoch: 1, idx: 226, curr loss: 0.25736697934553376\n",
      "epoch: 1, idx: 226, avg loss: 0.25736697934553376\n",
      "epoch: 1, idx: 227, curr loss: 0.2356176096664058\n",
      "epoch: 1, idx: 227, avg loss: 0.2356176096664058\n",
      "epoch: 1, idx: 228, curr loss: 0.17201805889271785\n",
      "epoch: 1, idx: 228, avg loss: 0.17201805889271785\n",
      "epoch: 1, idx: 229, curr loss: 0.21241577674572906\n",
      "epoch: 1, idx: 229, avg loss: 0.21241577674572906\n",
      "epoch: 1, idx: 230, curr loss: 0.20018657323453226\n",
      "epoch: 1, idx: 230, avg loss: 0.20018657323453226\n",
      "epoch: 1, idx: 231, curr loss: 0.13593662830226094\n",
      "epoch: 1, idx: 231, avg loss: 0.13593662830226094\n",
      "epoch: 1, idx: 232, curr loss: 0.23614297948643073\n",
      "epoch: 1, idx: 232, avg loss: 0.23614297948643073\n",
      "epoch: 1, idx: 233, curr loss: 0.21668329798103514\n",
      "epoch: 1, idx: 233, avg loss: 0.21668329798103514\n",
      "epoch: 1, idx: 234, curr loss: 0.22190528995179193\n",
      "epoch: 1, idx: 234, avg loss: 0.22190528995179193\n",
      "epoch: 1, idx: 235, curr loss: 0.3082200914407925\n",
      "epoch: 1, idx: 235, avg loss: 0.3082200914407925\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    tot_loss = 0\n",
    "    for train_idx, (train_data_batch, train_label_batch) in enumerate(zip(train_data, train_label)):\n",
    "        # train\n",
    "        preds = model.forward(train_data_batch)\n",
    "\n",
    "        loss = criterion.forward(preds, train_label_batch)\n",
    "        tot_loss += loss\n",
    "        propagated_error = criterion.error_derivative()\n",
    "\n",
    "        model.backprop(propagated_error)\n",
    "        model.optimize(LR)\n",
    "\n",
    "        print('epoch: {}, idx: {}, curr loss: {}'.format(epoch + 1, train_idx + 1, loss))\n",
    "        if train_idx == 0 or (train_idx + 1) % PRINT == 0:\n",
    "            if train_idx != 0:\n",
    "                tot_loss = tot_loss / PRINT\n",
    "            print('epoch: {}, idx: {}, avg loss: {}'.format(epoch + 1, train_idx + 1, tot_loss))\n",
    "            tot_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n",
      "481\n",
      "712\n",
      "947\n",
      "1172\n",
      "1409\n",
      "1639\n",
      "1879\n",
      "2110\n",
      "2352\n",
      "2589\n",
      "2833\n",
      "3071\n",
      "3309\n",
      "3539\n",
      "3773\n",
      "4004\n",
      "4238\n",
      "4473\n",
      "4712\n",
      "4962\n",
      "5211\n",
      "5457\n",
      "5690\n",
      "5939\n",
      "6180\n",
      "6425\n",
      "6676\n",
      "6930\n",
      "7177\n",
      "7421\n",
      "7674\n",
      "7919\n",
      "8172\n",
      "8427\n",
      "8673\n",
      "8924\n",
      "9172\n",
      "9395\n",
      "9411\n"
     ]
    }
   ],
   "source": [
    "tot_acc = 0\n",
    "tot_sample = 0\n",
    "for train_acc_idx, (test_data_batch, test_label_batch) in enumerate(zip(test_data, test_label)):\n",
    "    # train accuracy\n",
    "    preds = model.forward(test_data_batch)\n",
    "    preds = from_galois_to_real_domain(preds, QUANTIZATION_WEIGHT, PRIME)\n",
    "    pred_args = np.argmax(preds, axis=1)\n",
    "\n",
    "    tot_acc += np.count_nonzero(pred_args == test_label_batch)\n",
    "    tot_sample += test_data_batch.shape[0]\n",
    "    print(tot_acc)\n",
    "accuracy = tot_acc / tot_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

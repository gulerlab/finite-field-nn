{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-22T21:46:47.338296537Z",
     "start_time": "2023-06-22T21:46:46.171143266Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_all_data_mnist, load_all_data_cifar10, load_all_data_fashion_mnist, load_all_data_apply_vgg_cifar10\n",
    "from utils import create_batch_data\n",
    "import modules\n",
    "import layers\n",
    "from criterions import FiniteFieldMSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 5\n",
    "PRINT = 10\n",
    "FLATTEN = False\n",
    "# 0, MNIST; 1, FashionMNIST; 2, CIFAR10; 3, VGG-CIFAR10\n",
    "DATASET_MODE = 2\n",
    "PRIME = 2**26 - 5\n",
    "QUANTIZATION_WEIGHT = 8\n",
    "QUANTIZATION_INPUT = 8\n",
    "QUANTIZATION_BATCH_SIZE = 8\n",
    "LR = 7"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T21:46:48.137532300Z",
     "start_time": "2023-06-22T21:46:48.136552527Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# data fetching\n",
    "load_path = '../../data'\n",
    "if DATASET_MODE == 0:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_mnist(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 1:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_fashion_mnist(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 2:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_cifar10(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 3:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_apply_vgg_cifar10(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, flatten=FLATTEN)\n",
    "else:\n",
    "    train_data, train_label, test_data, test_label = None, None, None, None\n",
    "train_data, train_label, test_data, test_label = create_batch_data(train_data, train_label, test_data, test_label, BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-22T21:46:49.080502980Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_arr = [\n",
    "    layers.FiniteFieldPiNetSecondOrderConvLayer(3, 6, (9, 9), QUANTIZATION_WEIGHT, PRIME, first_layer=True, quantization_bit_input=QUANTIZATION_INPUT),\n",
    "    modules.Flatten(),\n",
    "    layers.FiniteFieldPiNetSecondOrderLinearLayer(3456, 128, QUANTIZATION_WEIGHT, PRIME),\n",
    "    layers.FiniteFieldLinearLayer(128, 10, QUANTIZATION_WEIGHT, PRIME)\n",
    "]\n",
    "\n",
    "model = modules.Network(model_arr)\n",
    "criterion = FiniteFieldMSELoss(PRIME, QUANTIZATION_WEIGHT, QUANTIZATION_BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T21:36:10.115349104Z",
     "start_time": "2023-06-22T21:36:10.099143553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, idx: 1, accuracy: 0.1269, loss: 1.3846830877451854\n",
      "epoch: 1, idx: 10, accuracy: 0.2125, loss: 0.955424733710205\n",
      "epoch: 1, idx: 20, accuracy: 0.2505, loss: 0.9470299719219636\n",
      "epoch: 1, idx: 30, accuracy: 0.273, loss: 0.9001624456508196\n",
      "epoch: 1, idx: 40, accuracy: 0.2853, loss: 0.8955623976716316\n",
      "epoch: 1, idx: 50, accuracy: 0.3061, loss: 0.8954912565571391\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    tot_loss = 0\n",
    "    for train_idx, (train_data_batch, train_label_batch) in enumerate(zip(train_data, train_label)):\n",
    "        # train\n",
    "        preds = model.forward(train_data_batch)\n",
    "\n",
    "        tot_loss += criterion.forward(preds, train_label_batch)\n",
    "        propagated_error = criterion.error_derivative()\n",
    "\n",
    "        model.backprop(propagated_error)\n",
    "        model.optimize(LR)\n",
    "\n",
    "        if train_idx == 0 or (train_idx + 1) % PRINT == 0:\n",
    "            tot_acc = 0\n",
    "            tot_sample = 0\n",
    "            for train_acc_idx, (test_data_batch, test_label_batch) in enumerate(zip(test_data, test_label)):\n",
    "                # train accuracy\n",
    "                preds = model.forward(test_data_batch)\n",
    "                pred_args = np.argmax(preds, axis=1)\n",
    "\n",
    "                tot_acc += np.count_nonzero(pred_args == test_label_batch)\n",
    "                tot_sample += test_data_batch.shape[0]\n",
    "            accuracy = tot_acc / tot_sample\n",
    "            if train_idx != 0:\n",
    "                tot_loss = tot_loss / PRINT\n",
    "            print('epoch: {}, idx: {}, accuracy: {}, loss: {}'.format(epoch + 1, train_idx + 1, accuracy, tot_loss))\n",
    "            tot_loss = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-22T21:36:15.590864109Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

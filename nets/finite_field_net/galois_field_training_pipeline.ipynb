{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:42.017217095Z",
     "start_time": "2023-06-23T11:38:40.967468871Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umityigitbsrn/miniconda3/envs/pytorch-stable/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from galois_datasets import load_all_data_mnist, load_all_data_cifar10, load_all_data_fashion_mnist\n",
    "from utils import create_batch_data, to_finite_field_domain, from_galois_to_real_domain\n",
    "import modules\n",
    "import galois_layers\n",
    "from galois_criterions import GaloisFieldMSELoss\n",
    "from sklearn.datasets import make_classification\n",
    "import galois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 100\n",
    "PRINT = 1\n",
    "FLATTEN = False\n",
    "# 0, MNIST; 1, FashionMNIST; 2, CIFAR10; 3 RANDOM\n",
    "DATASET_MODE = 3\n",
    "PRIME = 2**26 - 5\n",
    "QUANTIZATION_WEIGHT = 8\n",
    "QUANTIZATION_INPUT = 8\n",
    "QUANTIZATION_BATCH_SIZE = 8\n",
    "LR = 3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:42.019549983Z",
     "start_time": "2023-06-23T11:38:42.018499848Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "field = galois.GF(PRIME)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:43.271300923Z",
     "start_time": "2023-06-23T11:38:42.754454712Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# data fetching\n",
    "load_path = '../../data'\n",
    "if DATASET_MODE == 0:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_mnist(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, field, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 1:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_fashion_mnist(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, field, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 2:\n",
    "    train_data, train_label, test_data, test_label = load_all_data_cifar10(load_path, QUANTIZATION_INPUT, QUANTIZATION_WEIGHT, PRIME, field, flatten=FLATTEN)\n",
    "elif DATASET_MODE == 3:\n",
    "    train_data, train_label = make_classification(n_samples=10, n_features=100, n_classes=10, n_clusters_per_class=1, n_informative=10)\n",
    "    train_data = train_data.reshape((-1, 4, 5, 5))\n",
    "    test_data, test_label = train_data, train_label\n",
    "    train_label = np.zeros((10, 10))\n",
    "    for idx, label in enumerate(test_label):\n",
    "        train_label[idx][label] = 1\n",
    "    train_data, train_label, test_data = to_finite_field_domain(train_data, QUANTIZATION_INPUT, PRIME), to_finite_field_domain(train_label, QUANTIZATION_WEIGHT, PRIME), to_finite_field_domain(test_data, QUANTIZATION_INPUT, PRIME)\n",
    "    train_data, train_label, test_data = field(train_data), field(train_label), field(test_data)\n",
    "else:\n",
    "    train_data, train_label, test_data, test_label = None, None, None, None\n",
    "train_data, train_label, test_data, test_label = create_batch_data(train_data, train_label, test_data, test_label, BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:43.517528143Z",
     "start_time": "2023-06-23T11:38:43.512054166Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model_arr = [\n",
    "    galois_layers.GaloisFieldPiNetSecondOrderConvLayer(4, 6, (3, 3), QUANTIZATION_WEIGHT, PRIME, field, first_layer=True, padding=(2, 2, 2, 2), quantization_bit_input=QUANTIZATION_INPUT),\n",
    "    galois_layers.GaloisFieldPiNetSecondOrderConvLayer(6, 6, (5, 5), QUANTIZATION_WEIGHT, PRIME, field, padding=(2, 2, 2, 2)),\n",
    "    galois_layers.GaloisFieldPiNetSecondOrderConvLayer(6, 6, (3, 3), QUANTIZATION_WEIGHT, PRIME, field),\n",
    "    modules.Flatten(),\n",
    "    galois_layers.GaloisFieldPiNetSecondOrderLinearLayer(150, 64, QUANTIZATION_WEIGHT, PRIME, field),\n",
    "    galois_layers.GaloisFieldLinearLayer(64, 10, QUANTIZATION_WEIGHT, PRIME, field)\n",
    "]\n",
    "\n",
    "model = modules.Network(model_arr)\n",
    "criterion = GaloisFieldMSELoss(PRIME, QUANTIZATION_WEIGHT, QUANTIZATION_BATCH_SIZE, field)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T11:38:44.174933932Z",
     "start_time": "2023-06-23T11:38:44.172059964Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, idx: 1, accuracy: 0.0, loss: 1.0821487426757812\n",
      "epoch: 2, idx: 1, accuracy: 0.0, loss: 1.0798446655273437\n",
      "epoch: 3, idx: 1, accuracy: 0.0, loss: 1.064555358886719\n",
      "epoch: 4, idx: 1, accuracy: 0.0, loss: 1.0538528442382813\n",
      "epoch: 5, idx: 1, accuracy: 0.0, loss: 1.0412399291992187\n",
      "epoch: 6, idx: 1, accuracy: 0.0, loss: 1.0454849243164062\n",
      "epoch: 7, idx: 1, accuracy: 0.1, loss: 1.0278961181640622\n",
      "epoch: 8, idx: 1, accuracy: 0.1, loss: 1.0112747192382812\n",
      "epoch: 9, idx: 1, accuracy: 0.1, loss: 0.9921173095703125\n",
      "epoch: 10, idx: 1, accuracy: 0.1, loss: 0.9770385742187498\n",
      "epoch: 11, idx: 1, accuracy: 0.1, loss: 0.9614700317382813\n",
      "epoch: 12, idx: 1, accuracy: 0.2, loss: 0.9517623901367187\n",
      "epoch: 13, idx: 1, accuracy: 0.5, loss: 0.9428924560546875\n",
      "epoch: 14, idx: 1, accuracy: 0.5, loss: 0.9190597534179685\n",
      "epoch: 15, idx: 1, accuracy: 0.6, loss: 0.9126754760742187\n",
      "epoch: 16, idx: 1, accuracy: 0.6, loss: 0.8967117309570314\n",
      "epoch: 17, idx: 1, accuracy: 0.5, loss: 0.8765075683593748\n",
      "epoch: 18, idx: 1, accuracy: 0.6, loss: 0.87645263671875\n",
      "epoch: 19, idx: 1, accuracy: 0.7, loss: 0.8628448486328125\n",
      "epoch: 20, idx: 1, accuracy: 0.7, loss: 0.8443252563476562\n",
      "epoch: 21, idx: 1, accuracy: 0.5, loss: 0.8513229370117188\n",
      "epoch: 22, idx: 1, accuracy: 0.7, loss: 0.8343780517578125\n",
      "epoch: 23, idx: 1, accuracy: 0.6, loss: 0.8055267333984377\n",
      "epoch: 24, idx: 1, accuracy: 0.7, loss: 0.7802963256835938\n",
      "epoch: 25, idx: 1, accuracy: 0.7, loss: 0.7696990966796875\n",
      "epoch: 26, idx: 1, accuracy: 0.8, loss: 0.7508621215820311\n",
      "epoch: 27, idx: 1, accuracy: 0.9, loss: 0.733575439453125\n",
      "epoch: 28, idx: 1, accuracy: 0.9, loss: 0.7238510131835938\n",
      "epoch: 29, idx: 1, accuracy: 1.0, loss: 0.7101699829101562\n",
      "epoch: 30, idx: 1, accuracy: 1.0, loss: 0.6732955932617186\n",
      "epoch: 31, idx: 1, accuracy: 0.9, loss: 0.6951339721679688\n",
      "epoch: 32, idx: 1, accuracy: 1.0, loss: 0.6701522827148436\n",
      "epoch: 33, idx: 1, accuracy: 0.9, loss: 0.63145751953125\n",
      "epoch: 34, idx: 1, accuracy: 0.9, loss: 0.618109130859375\n",
      "epoch: 35, idx: 1, accuracy: 0.9, loss: 0.6444519042968749\n",
      "epoch: 36, idx: 1, accuracy: 0.8, loss: 0.6375396728515624\n",
      "epoch: 37, idx: 1, accuracy: 0.9, loss: 0.5917526245117186\n",
      "epoch: 38, idx: 1, accuracy: 0.9, loss: 0.58636474609375\n",
      "epoch: 39, idx: 1, accuracy: 0.8, loss: 0.6195236206054688\n",
      "epoch: 40, idx: 1, accuracy: 0.7, loss: 0.6370178222656249\n",
      "epoch: 41, idx: 1, accuracy: 0.8, loss: 0.584381103515625\n",
      "epoch: 42, idx: 1, accuracy: 0.7, loss: 0.59505615234375\n",
      "epoch: 43, idx: 1, accuracy: 0.9, loss: 0.5950714111328124\n",
      "epoch: 44, idx: 1, accuracy: 0.8, loss: 0.5984725952148439\n",
      "epoch: 45, idx: 1, accuracy: 0.8, loss: 0.6017410278320312\n",
      "epoch: 46, idx: 1, accuracy: 0.7, loss: 0.6059722900390624\n",
      "epoch: 47, idx: 1, accuracy: 0.8, loss: 0.5881698608398438\n",
      "epoch: 48, idx: 1, accuracy: 0.8, loss: 0.5586837768554687\n",
      "epoch: 49, idx: 1, accuracy: 0.8, loss: 0.5138168334960938\n",
      "epoch: 50, idx: 1, accuracy: 0.8, loss: 0.5130126953125\n",
      "epoch: 51, idx: 1, accuracy: 0.8, loss: 0.519183349609375\n",
      "epoch: 52, idx: 1, accuracy: 0.8, loss: 0.5127960205078125\n",
      "epoch: 53, idx: 1, accuracy: 0.8, loss: 0.5188827514648439\n",
      "epoch: 54, idx: 1, accuracy: 0.8, loss: 0.513934326171875\n",
      "epoch: 55, idx: 1, accuracy: 0.9, loss: 0.5057632446289063\n",
      "epoch: 56, idx: 1, accuracy: 1.0, loss: 0.4733154296874999\n",
      "epoch: 57, idx: 1, accuracy: 0.9, loss: 0.47871093749999993\n",
      "epoch: 58, idx: 1, accuracy: 0.9, loss: 0.477044677734375\n",
      "epoch: 59, idx: 1, accuracy: 1.0, loss: 0.4782562255859376\n",
      "epoch: 60, idx: 1, accuracy: 1.0, loss: 0.45995635986328115\n",
      "epoch: 61, idx: 1, accuracy: 1.0, loss: 0.44034576416015636\n",
      "epoch: 62, idx: 1, accuracy: 1.0, loss: 0.44668426513671877\n",
      "epoch: 63, idx: 1, accuracy: 1.0, loss: 0.43786773681640623\n",
      "epoch: 64, idx: 1, accuracy: 1.0, loss: 0.4113433837890625\n",
      "epoch: 65, idx: 1, accuracy: 1.0, loss: 0.39285125732421877\n",
      "epoch: 66, idx: 1, accuracy: 1.0, loss: 0.396746826171875\n",
      "epoch: 67, idx: 1, accuracy: 1.0, loss: 0.3812179565429687\n",
      "epoch: 68, idx: 1, accuracy: 1.0, loss: 0.4055526733398437\n",
      "epoch: 69, idx: 1, accuracy: 1.0, loss: 0.38007965087890627\n",
      "epoch: 70, idx: 1, accuracy: 1.0, loss: 0.3788742065429687\n",
      "epoch: 71, idx: 1, accuracy: 1.0, loss: 0.37960510253906243\n",
      "epoch: 72, idx: 1, accuracy: 1.0, loss: 0.38656768798828123\n",
      "epoch: 73, idx: 1, accuracy: 1.0, loss: 0.38140563964843743\n",
      "epoch: 74, idx: 1, accuracy: 1.0, loss: 0.36548614501953125\n",
      "epoch: 75, idx: 1, accuracy: 1.0, loss: 0.380853271484375\n",
      "epoch: 76, idx: 1, accuracy: 1.0, loss: 0.358099365234375\n",
      "epoch: 77, idx: 1, accuracy: 1.0, loss: 0.37163848876953126\n",
      "epoch: 78, idx: 1, accuracy: 1.0, loss: 0.37388000488281253\n",
      "epoch: 79, idx: 1, accuracy: 1.0, loss: 0.3441879272460938\n",
      "epoch: 80, idx: 1, accuracy: 0.9, loss: 0.35934448242187506\n",
      "epoch: 81, idx: 1, accuracy: 1.0, loss: 0.4064819335937499\n",
      "epoch: 82, idx: 1, accuracy: 1.0, loss: 0.39119873046875003\n",
      "epoch: 83, idx: 1, accuracy: 0.9, loss: 0.4012664794921874\n",
      "epoch: 84, idx: 1, accuracy: 1.0, loss: 0.432781982421875\n",
      "epoch: 85, idx: 1, accuracy: 1.0, loss: 0.39752502441406257\n",
      "epoch: 86, idx: 1, accuracy: 1.0, loss: 0.428167724609375\n",
      "epoch: 87, idx: 1, accuracy: 0.9, loss: 0.4062072753906249\n",
      "epoch: 88, idx: 1, accuracy: 0.9, loss: 0.4425964355468751\n",
      "epoch: 89, idx: 1, accuracy: 0.9, loss: 1.016064453125\n",
      "epoch: 90, idx: 1, accuracy: 1.0, loss: 0.4663864135742187\n",
      "epoch: 91, idx: 1, accuracy: 1.0, loss: 0.34192962646484376\n",
      "epoch: 92, idx: 1, accuracy: 1.0, loss: 0.32646026611328127\n",
      "epoch: 93, idx: 1, accuracy: 1.0, loss: 0.33289337158203125\n",
      "epoch: 94, idx: 1, accuracy: 1.0, loss: 0.43448944091796876\n",
      "epoch: 95, idx: 1, accuracy: 1.0, loss: 0.3420974731445312\n",
      "epoch: 96, idx: 1, accuracy: 1.0, loss: 0.36726531982421873\n",
      "epoch: 97, idx: 1, accuracy: 1.0, loss: 0.33404083251953126\n",
      "epoch: 98, idx: 1, accuracy: 1.0, loss: 0.3851715087890625\n",
      "epoch: 99, idx: 1, accuracy: 1.0, loss: 0.34986877441406256\n",
      "epoch: 100, idx: 1, accuracy: 1.0, loss: 0.42851104736328127\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    tot_loss = 0\n",
    "    for train_idx, (train_data_batch, train_label_batch) in enumerate(zip(train_data, train_label)):\n",
    "        # train\n",
    "        preds = model.forward(train_data_batch)\n",
    "\n",
    "        loss = criterion.forward(preds, train_label_batch)\n",
    "        tot_loss += loss\n",
    "        propagated_error = criterion.error_derivative()\n",
    "\n",
    "        model.backprop(propagated_error)\n",
    "        model.optimize(LR)\n",
    "\n",
    "        if (train_idx + 1) % PRINT == 0:\n",
    "            tot_acc = 0\n",
    "            tot_sample = 0\n",
    "            for train_acc_idx, (test_data_batch, test_label_batch) in enumerate(zip(test_data, test_label)):\n",
    "                # train accuracy\n",
    "                preds = model.forward(test_data_batch)\n",
    "                preds = from_galois_to_real_domain(preds, QUANTIZATION_WEIGHT, PRIME)\n",
    "                pred_args = np.argmax(preds, axis=1)\n",
    "\n",
    "                tot_acc += np.count_nonzero(pred_args == test_label_batch)\n",
    "                tot_sample += test_data_batch.shape[0]\n",
    "            accuracy = tot_acc / tot_sample\n",
    "            if train_idx != 0:\n",
    "                tot_loss = tot_loss / PRINT\n",
    "            print('epoch: {}, idx: {}, accuracy: {}, loss: {}'.format(epoch + 1, train_idx + 1, accuracy, tot_loss))\n",
    "            tot_loss = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T11:41:20.925984317Z",
     "start_time": "2023-06-23T11:38:45.014257135Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
